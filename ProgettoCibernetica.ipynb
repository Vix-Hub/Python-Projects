{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProgettoCibernetica.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNG7bAvH4CzHHgehfNHDNcL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vix-Hub/Python-Projects/blob/master/ProgettoCibernetica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtbauVV6z_Ti",
        "outputId": "a930b1bf-1edb-4779-a622-af206fedced7"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "def vectorized_result(j):\n",
        "    e = np.zeros((10, 1))\n",
        "    e[j] = 1.0\n",
        "    return e\n",
        "\n",
        "def load():\n",
        "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    x_train = x_train.reshape(x_train.shape[0], 784,)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 784,)\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    \n",
        "    mean_vals = np.mean(x_train, axis=0)\n",
        "    std_val = np.std(x_train)\n",
        "    \n",
        "    X_train_centered = (x_train - mean_vals)/std_val\n",
        "    X_test_centered = (x_test - mean_vals)/std_val\n",
        "    \n",
        "    return X_train_centered, y_train, X_test_centered, y_test\n",
        "\n",
        "\n",
        "#mini batch [10-150], eta [0.00001-1], nh [15-90]\n",
        "\n",
        "X_train, y_train, X_test, y_test = load()\n",
        "\n",
        "class MLP(object):\n",
        "    \n",
        "    def __init__(self, n_hidden, eta, mini_batch_size):\n",
        "        self.n_hidden = n_hidden\n",
        "        self.eta = eta\n",
        "        self.minibatch_size = mini_batch_size\n",
        "        self.eval_ = {'loss': []}\n",
        "        \n",
        "    def create_batch_generator(self,X, y, batch_size=128, shuffle=False):\n",
        "        X_copy = np.array(X)\n",
        "        y_copy = np.array(y)\n",
        "    \n",
        "        if shuffle:\n",
        "            data = np.column_stack((X_copy, y_copy))\n",
        "            np.random.shuffle(data)\n",
        "            X_copy = data[:, :-1]\n",
        "            y_copy = data[:, -1].astype(int)\n",
        "    \n",
        "        for i in range(0, X.shape[0], batch_size):\n",
        "            yield (X_copy[i:i+batch_size, :], y_copy[i:i+batch_size])\n",
        "            \n",
        "    def fit(self, X_train, y_train, X_test, y_test, epochs):\n",
        "           \n",
        "            n_features = X_train.shape[1]\n",
        "            n_classes = 10\n",
        "            random_seed = 123\n",
        "            np.random.seed(random_seed)\n",
        "    \n",
        "            g1 = tf.Graph()\n",
        "            with g1.as_default():\n",
        "                tf.set_random_seed(random_seed)\n",
        "                tf_x = tf.placeholder(dtype=tf.float32,\n",
        "                           shape=(None, n_features),\n",
        "                           name='tf_x')\n",
        "    \n",
        "                tf_y = tf.placeholder(dtype=tf.int32, \n",
        "                            shape=None, name='tf_y')\n",
        "                y_onehot = tf.one_hot(indices=tf_y, depth=n_classes)\n",
        "    \n",
        "                h1 = tf.layers.dense(inputs=tf_x, units=self.n_hidden,\n",
        "                             activation=tf.sigmoid,\n",
        "                             name='layer1')\n",
        "    \n",
        "                logits = tf.layers.dense(inputs=h1, \n",
        "                                 units=10,\n",
        "                                 activation=None,\n",
        "                                 name='layer3')\n",
        "    \n",
        "                predictions = {\n",
        "                        'classes' : tf.argmax(logits, axis=1, \n",
        "                                  name='predicted_classes'),\n",
        "                        'probabilities' : tf.nn.softmax(logits, \n",
        "                                  name='softmax_tensor')\n",
        "                        }\n",
        "            with g1.as_default():\n",
        "                cost = tf.losses.mean_squared_error(labels=y_onehot, predictions = logits)\n",
        "    \n",
        "                optimizer = tf.train.GradientDescentOptimizer(\n",
        "                        learning_rate=self.eta)\n",
        "    \n",
        "                train_op = optimizer.minimize(loss=cost)\n",
        "    \n",
        "                init_op = tf.global_variables_initializer()\n",
        "                sess =  tf.Session(graph=g1)\n",
        "                sess.run(init_op)\n",
        "                \n",
        "                t1 = datetime.now()\n",
        "                training_costs = []\n",
        "                for epoch in range(epochs):\n",
        "                    batch_generator = self.create_batch_generator(\n",
        "                            X_train, y_train, \n",
        "                            batch_size=self.minibatch_size, shuffle = False)\n",
        "                    for batch_X, batch_y in batch_generator:\n",
        "            \n",
        "                        feed = {tf_x:batch_X, tf_y:batch_y}\n",
        "                        _, batch_cost = sess.run([train_op, cost],\n",
        "                                     feed_dict=feed)\n",
        "                        training_costs.append(batch_cost)\n",
        "                    print(' -- Epoch %2d  '\n",
        "                             'Avg. Training Loss: %.4f' % (\n",
        "                                     epoch+1, np.mean(training_costs)\n",
        "                            ))\n",
        "                    self.eval_['loss'].append(np.mean(training_costs))\n",
        "    \n",
        "                feed = {tf_x : X_test}\n",
        "                y_pred = sess.run(predictions['classes'], \n",
        "                                  feed_dict=feed)\n",
        "     \n",
        "                acc = np.sum(y_pred == y_test)/y_test.shape[0]\n",
        "                t2 = datetime.now()\n",
        "                print(t2-t1)\n",
        "                sess.close()\n",
        "                return acc\n",
        "    \n",
        "    def plot(self):\n",
        "        \n",
        "        plt.plot(range(len(self.eval_['loss'])), self.eval_['loss'])\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Cost')\n",
        "        plt.title('Cost Function')\n",
        "        plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CRwLPreO0kWA",
        "outputId": "c813918a-cf3c-4b3d-aba1-e5aaf695bcac"
      },
      "source": [
        "import random as r \n",
        "!pip install deap\n",
        "from deap import base, creator, tools\n",
        "from time import sleep\n",
        "import sys \n",
        "\n",
        "X_train, y_train, X_test, y_test = load()\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights = (1.0,))\n",
        "creator.create(\"Individual\", list, fitness = creator.FitnessMax)\n",
        "c_1, d_1, c_2, d_2 = int(input(\"Inserire il range neuroni nascosti e grandezza minibatch: c1 = \")), int(input(\"Inserire d1 \")), int(input(\"Inserire c2 \")), int(input(\"Inserire d2 \"))\n",
        "c_3, d_3 = float(input(\"Range per learning rate: \")), float(input(\"d3 \"))\n",
        "\n",
        "acc = {'acc': [], 'avg': []}\n",
        "\n",
        "func_seq = [lambda:r.randint(c_1,d_1), lambda:r.randint(c_2,d_2), lambda: r.random()*(d_3-c_3)]\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
        "                 func_seq, n=1)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual, 80)\n",
        "\n",
        "def evaluate(Individual):\n",
        "    net = MLP(Individual[0], Individual[2], Individual[1])\n",
        "    return net.fit(X_train, y_train, X_test, y_test, 10),\n",
        "    \n",
        "def new_mut(Individual, indpb = 0.15):\n",
        "    l1= [0,0,0]\n",
        "    if (r.random() < indpb):\n",
        "        l1[0] = (r.gauss(mu = Individual[0], sigma =1))\n",
        "    if (r.random() < indpb):\n",
        "        l1[1] = (r.gauss(mu = Individual[1], sigma =1))\n",
        "    if (r.random() < indpb):\n",
        "        l1[2] = (r.gauss(mu = Individual[2], sigma =0.1))\n",
        "    return [abs(int(l1[0])), abs(int(l1[1])), abs(l1[2])]\n",
        "    \n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "toolbox.register(\"mate\", tools.cxUniform)\n",
        "toolbox.register(\"mutate\", new_mut)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize = 3, fit_attr='fitness')\n",
        "\n",
        "def main():\n",
        "    t1 = datetime.now()\n",
        "    print(t1)\n",
        "    pop = toolbox.population()\n",
        "    CXPB, MUTPB, NGEN = 0.4, 0.2, 10\n",
        "    \n",
        "    fitnesses = list(map(toolbox.evaluate, pop))\n",
        "    for ind, fit in zip(pop, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "    \n",
        "    for g in range(NGEN):\n",
        "        offspring = toolbox.select(pop, len(pop))\n",
        "        offspring = list(map(toolbox.clone,offspring))\n",
        "        \n",
        "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "            if(r.random() < CXPB):\n",
        "                toolbox.mate(child1, child2, indpb = 0.2)\n",
        "                del child1.fitness.values\n",
        "                del child2.fitness.values\n",
        "            \n",
        "        for mutant in offspring:\n",
        "            if(r.random() < MUTPB):\n",
        "                toolbox.mutate(mutant)\n",
        "                del mutant.fitness.values\n",
        "        \n",
        "        individui_da_valutare = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = list(map(toolbox.evaluate, individui_da_valutare))\n",
        "        for ind, fit in zip(individui_da_valutare, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "        avg = 0.\n",
        "        fits = []\n",
        "        for ind in pop:\n",
        "            avg+=ind.fitness.values[0]\n",
        "            fits.append(ind.fitness.values[0])\n",
        "        avg = avg/len(pop)\n",
        "        acc['avg'].append(avg)\n",
        "        \n",
        "        index = np.argmax(fits)\n",
        "        acc['acc'].append(fits[index])\n",
        "           \n",
        "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int((g+1)*20/NGEN), (100/NGEN)*(g+1)))\n",
        "        sys.stdout.flush()\n",
        "        sleep(0.25)\n",
        "        \n",
        "        pop[:] = offspring\n",
        "        \n",
        "        pop_2 = [list(ind) for ind in pop]\n",
        "        \n",
        "        if len(np.unique(pop_2, axis = 0)) <=5:\n",
        "            print('Last Gen ' +str(g+1))\n",
        "            plt.plot(range(len(acc['avg'])), acc['avg'])\n",
        "            plt.xlabel('Generations')\n",
        "            plt.ylabel('Average Fitness')\n",
        "            plt.show()\n",
        "            plt.plot(range(len(acc['acc'])), acc['acc'])\n",
        "            plt.xlabel('Generations')\n",
        "            plt.ylabel('Best Fitness')\n",
        "            plt.title('Best Fitness vs Generations')\n",
        "            plt.show()\n",
        "            print(pop)\n",
        "            t2 = datetime.now()\n",
        "            print(t2-t1)\n",
        "            break\n",
        "        t2 = datetime.now() \n",
        "        print(t2-t1)\n",
        "        print(\"Generation #\" + str(g))\n",
        "      \n",
        "    results = []\n",
        "    for ind in pop:\n",
        "        results.append((ind, ind.fitness.values))\n",
        "    \n",
        "    plt.plot(range(len(acc['avg'])), acc['avg'])\n",
        "    plt.xlabel('Generations')\n",
        "    plt.ylabel('Average Fitness')\n",
        "    plt.title('Average Fitness vs Generations')\n",
        "    plt.show()\n",
        "    plt.plot(range(len(acc['acc'])), acc['acc'])\n",
        "    plt.xlabel('Generations')\n",
        "    plt.ylabel('Best Fitness')\n",
        "    plt.title('Best Fitness vs Generations')\n",
        "    plt.show()\n",
        "    t2 = datetime.now()\n",
        "    print(t2-t1)\n",
        "    return results\n",
        "\n",
        "#mini batch [10-150], eta [0.00001-1], nh [15-90]\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/eb/2bd0a32e3ce757fb26264765abbaedd6d4d3640d90219a513aeabd08ee2b/deap-1.3.1-cp36-cp36m-manylinux2010_x86_64.whl (157kB)\n",
            "\r\u001b[K     |██                              | 10kB 31.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 35.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 30kB 20.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 40kB 23.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51kB 23.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 61kB 25.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 71kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 81kB 18.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 92kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 102kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 112kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 122kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 133kB 17.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 143kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 153kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deap) (1.19.4)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.1\n",
            "2021-01-06 07:31:43.146953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " -- Epoch  1  Avg. Training Loss: 0.0485\n",
            " -- Epoch  2  Avg. Training Loss: 0.0423\n",
            " -- Epoch  3  Avg. Training Loss: 0.0392\n",
            " -- Epoch  4  Avg. Training Loss: 0.0372\n",
            " -- Epoch  5  Avg. Training Loss: 0.0358\n",
            " -- Epoch  6  Avg. Training Loss: 0.0346\n",
            " -- Epoch  7  Avg. Training Loss: 0.0337\n",
            " -- Epoch  8  Avg. Training Loss: 0.0329\n",
            " -- Epoch  9  Avg. Training Loss: 0.0323\n",
            " -- Epoch 10  Avg. Training Loss: 0.0317\n",
            "0:00:07.760049\n",
            " -- Epoch  1  Avg. Training Loss: 0.0620\n",
            " -- Epoch  2  Avg. Training Loss: 0.0524\n",
            " -- Epoch  3  Avg. Training Loss: 0.0480\n",
            " -- Epoch  4  Avg. Training Loss: 0.0452\n",
            " -- Epoch  5  Avg. Training Loss: 0.0432\n",
            " -- Epoch  6  Avg. Training Loss: 0.0417\n",
            " -- Epoch  7  Avg. Training Loss: 0.0405\n",
            " -- Epoch  8  Avg. Training Loss: 0.0395\n",
            " -- Epoch  9  Avg. Training Loss: 0.0387\n",
            " -- Epoch 10  Avg. Training Loss: 0.0380\n",
            "0:00:06.321481\n",
            " -- Epoch  1  Avg. Training Loss: 0.0576\n",
            " -- Epoch  2  Avg. Training Loss: 0.0499\n",
            " -- Epoch  3  Avg. Training Loss: 0.0461\n",
            " -- Epoch  4  Avg. Training Loss: 0.0437\n",
            " -- Epoch  5  Avg. Training Loss: 0.0419\n",
            " -- Epoch  6  Avg. Training Loss: 0.0405\n",
            " -- Epoch  7  Avg. Training Loss: 0.0394\n",
            " -- Epoch  8  Avg. Training Loss: 0.0385\n",
            " -- Epoch  9  Avg. Training Loss: 0.0377\n",
            " -- Epoch 10  Avg. Training Loss: 0.0370\n",
            "0:00:06.626902\n",
            " -- Epoch  1  Avg. Training Loss: 0.0457\n",
            " -- Epoch  2  Avg. Training Loss: 0.0397\n",
            " -- Epoch  3  Avg. Training Loss: 0.0369\n",
            " -- Epoch  4  Avg. Training Loss: 0.0352\n",
            " -- Epoch  5  Avg. Training Loss: 0.0340\n",
            " -- Epoch  6  Avg. Training Loss: 0.0331\n",
            " -- Epoch  7  Avg. Training Loss: 0.0323\n",
            " -- Epoch  8  Avg. Training Loss: 0.0317\n",
            " -- Epoch  9  Avg. Training Loss: 0.0312\n",
            " -- Epoch 10  Avg. Training Loss: 0.0308\n",
            "0:00:05.987266\n",
            " -- Epoch  1  Avg. Training Loss: 0.0962\n",
            " -- Epoch  2  Avg. Training Loss: 0.0798\n",
            " -- Epoch  3  Avg. Training Loss: 0.0722\n",
            " -- Epoch  4  Avg. Training Loss: 0.0674\n",
            " -- Epoch  5  Avg. Training Loss: 0.0640\n",
            " -- Epoch  6  Avg. Training Loss: 0.0614\n",
            " -- Epoch  7  Avg. Training Loss: 0.0593\n",
            " -- Epoch  8  Avg. Training Loss: 0.0576\n",
            " -- Epoch  9  Avg. Training Loss: 0.0562\n",
            " -- Epoch 10  Avg. Training Loss: 0.0549\n",
            "0:00:21.942782\n",
            " -- Epoch  1  Avg. Training Loss: 0.0597\n",
            " -- Epoch  2  Avg. Training Loss: 0.0513\n",
            " -- Epoch  3  Avg. Training Loss: 0.0473\n",
            " -- Epoch  4  Avg. Training Loss: 0.0448\n",
            " -- Epoch  5  Avg. Training Loss: 0.0430\n",
            " -- Epoch  6  Avg. Training Loss: 0.0416\n",
            " -- Epoch  7  Avg. Training Loss: 0.0405\n",
            " -- Epoch  8  Avg. Training Loss: 0.0396\n",
            " -- Epoch  9  Avg. Training Loss: 0.0388\n",
            " -- Epoch 10  Avg. Training Loss: 0.0381\n",
            "0:00:06.233960\n",
            " -- Epoch  1  Avg. Training Loss: 0.0659\n",
            " -- Epoch  2  Avg. Training Loss: 0.0556\n",
            " -- Epoch  3  Avg. Training Loss: 0.0510\n",
            " -- Epoch  4  Avg. Training Loss: 0.0481\n",
            " -- Epoch  5  Avg. Training Loss: 0.0461\n",
            " -- Epoch  6  Avg. Training Loss: 0.0445\n",
            " -- Epoch  7  Avg. Training Loss: 0.0433\n",
            " -- Epoch  8  Avg. Training Loss: 0.0423\n",
            " -- Epoch  9  Avg. Training Loss: 0.0414\n",
            " -- Epoch 10  Avg. Training Loss: 0.0407\n",
            "0:00:10.506259\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.526737\n",
            " -- Epoch  1  Avg. Training Loss: 0.0481\n",
            " -- Epoch  2  Avg. Training Loss: 0.0421\n",
            " -- Epoch  3  Avg. Training Loss: 0.0392\n",
            " -- Epoch  4  Avg. Training Loss: 0.0372\n",
            " -- Epoch  5  Avg. Training Loss: 0.0358\n",
            " -- Epoch  6  Avg. Training Loss: 0.0347\n",
            " -- Epoch  7  Avg. Training Loss: 0.0338\n",
            " -- Epoch  8  Avg. Training Loss: 0.0330\n",
            " -- Epoch  9  Avg. Training Loss: 0.0324\n",
            " -- Epoch 10  Avg. Training Loss: 0.0318\n",
            "0:00:10.204669\n",
            " -- Epoch  1  Avg. Training Loss: 0.0420\n",
            " -- Epoch  2  Avg. Training Loss: 0.0370\n",
            " -- Epoch  3  Avg. Training Loss: 0.0344\n",
            " -- Epoch  4  Avg. Training Loss: 0.0328\n",
            " -- Epoch  5  Avg. Training Loss: 0.0316\n",
            " -- Epoch  6  Avg. Training Loss: 0.0307\n",
            " -- Epoch  7  Avg. Training Loss: 0.0300\n",
            " -- Epoch  8  Avg. Training Loss: 0.0293\n",
            " -- Epoch  9  Avg. Training Loss: 0.0288\n",
            " -- Epoch 10  Avg. Training Loss: 0.0284\n",
            "0:00:09.245982\n",
            " -- Epoch  1  Avg. Training Loss: 0.0432\n",
            " -- Epoch  2  Avg. Training Loss: 0.0382\n",
            " -- Epoch  3  Avg. Training Loss: 0.0357\n",
            " -- Epoch  4  Avg. Training Loss: 0.0340\n",
            " -- Epoch  5  Avg. Training Loss: 0.0327\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0309\n",
            " -- Epoch  8  Avg. Training Loss: 0.0303\n",
            " -- Epoch  9  Avg. Training Loss: 0.0297\n",
            " -- Epoch 10  Avg. Training Loss: 0.0292\n",
            "0:00:21.652065\n",
            " -- Epoch  1  Avg. Training Loss: 0.0486\n",
            " -- Epoch  2  Avg. Training Loss: 0.0422\n",
            " -- Epoch  3  Avg. Training Loss: 0.0391\n",
            " -- Epoch  4  Avg. Training Loss: 0.0372\n",
            " -- Epoch  5  Avg. Training Loss: 0.0357\n",
            " -- Epoch  6  Avg. Training Loss: 0.0346\n",
            " -- Epoch  7  Avg. Training Loss: 0.0336\n",
            " -- Epoch  8  Avg. Training Loss: 0.0329\n",
            " -- Epoch  9  Avg. Training Loss: 0.0322\n",
            " -- Epoch 10  Avg. Training Loss: 0.0316\n",
            "0:00:06.113567\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0400\n",
            " -- Epoch  3  Avg. Training Loss: 0.0370\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0337\n",
            " -- Epoch  6  Avg. Training Loss: 0.0326\n",
            " -- Epoch  7  Avg. Training Loss: 0.0318\n",
            " -- Epoch  8  Avg. Training Loss: 0.0310\n",
            " -- Epoch  9  Avg. Training Loss: 0.0304\n",
            " -- Epoch 10  Avg. Training Loss: 0.0299\n",
            "0:00:08.632734\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.239010\n",
            " -- Epoch  1  Avg. Training Loss: 0.0602\n",
            " -- Epoch  2  Avg. Training Loss: 0.0518\n",
            " -- Epoch  3  Avg. Training Loss: 0.0477\n",
            " -- Epoch  4  Avg. Training Loss: 0.0452\n",
            " -- Epoch  5  Avg. Training Loss: 0.0433\n",
            " -- Epoch  6  Avg. Training Loss: 0.0419\n",
            " -- Epoch  7  Avg. Training Loss: 0.0408\n",
            " -- Epoch  8  Avg. Training Loss: 0.0398\n",
            " -- Epoch  9  Avg. Training Loss: 0.0390\n",
            " -- Epoch 10  Avg. Training Loss: 0.0383\n",
            "0:00:08.477637\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:07.654266\n",
            " -- Epoch  1  Avg. Training Loss: 0.0381\n",
            " -- Epoch  2  Avg. Training Loss: 0.0335\n",
            " -- Epoch  3  Avg. Training Loss: 0.0314\n",
            " -- Epoch  4  Avg. Training Loss: 0.0300\n",
            " -- Epoch  5  Avg. Training Loss: 0.0291\n",
            " -- Epoch  6  Avg. Training Loss: 0.0283\n",
            " -- Epoch  7  Avg. Training Loss: 0.0277\n",
            " -- Epoch  8  Avg. Training Loss: 0.0273\n",
            " -- Epoch  9  Avg. Training Loss: 0.0269\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:00:17.023565\n",
            " -- Epoch  1  Avg. Training Loss: 0.0518\n",
            " -- Epoch  2  Avg. Training Loss: 0.0454\n",
            " -- Epoch  3  Avg. Training Loss: 0.0422\n",
            " -- Epoch  4  Avg. Training Loss: 0.0401\n",
            " -- Epoch  5  Avg. Training Loss: 0.0386\n",
            " -- Epoch  6  Avg. Training Loss: 0.0374\n",
            " -- Epoch  7  Avg. Training Loss: 0.0365\n",
            " -- Epoch  8  Avg. Training Loss: 0.0356\n",
            " -- Epoch  9  Avg. Training Loss: 0.0349\n",
            " -- Epoch 10  Avg. Training Loss: 0.0343\n",
            "0:00:06.918208\n",
            " -- Epoch  1  Avg. Training Loss: 0.0588\n",
            " -- Epoch  2  Avg. Training Loss: 0.0482\n",
            " -- Epoch  3  Avg. Training Loss: 0.0434\n",
            " -- Epoch  4  Avg. Training Loss: 0.0405\n",
            " -- Epoch  5  Avg. Training Loss: 0.0385\n",
            " -- Epoch  6  Avg. Training Loss: 0.0369\n",
            " -- Epoch  7  Avg. Training Loss: 0.0357\n",
            " -- Epoch  8  Avg. Training Loss: 0.0347\n",
            " -- Epoch  9  Avg. Training Loss: 0.0338\n",
            " -- Epoch 10  Avg. Training Loss: 0.0330\n",
            "0:00:08.169674\n",
            " -- Epoch  1  Avg. Training Loss: 0.0511\n",
            " -- Epoch  2  Avg. Training Loss: 0.0446\n",
            " -- Epoch  3  Avg. Training Loss: 0.0414\n",
            " -- Epoch  4  Avg. Training Loss: 0.0393\n",
            " -- Epoch  5  Avg. Training Loss: 0.0378\n",
            " -- Epoch  6  Avg. Training Loss: 0.0367\n",
            " -- Epoch  7  Avg. Training Loss: 0.0357\n",
            " -- Epoch  8  Avg. Training Loss: 0.0349\n",
            " -- Epoch  9  Avg. Training Loss: 0.0342\n",
            " -- Epoch 10  Avg. Training Loss: 0.0336\n",
            "0:00:06.582088\n",
            " -- Epoch  1  Avg. Training Loss: 0.0426\n",
            " -- Epoch  2  Avg. Training Loss: 0.0374\n",
            " -- Epoch  3  Avg. Training Loss: 0.0348\n",
            " -- Epoch  4  Avg. Training Loss: 0.0331\n",
            " -- Epoch  5  Avg. Training Loss: 0.0319\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0301\n",
            " -- Epoch  8  Avg. Training Loss: 0.0295\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0284\n",
            "0:00:12.481765\n",
            " -- Epoch  1  Avg. Training Loss: 0.0446\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0346\n",
            " -- Epoch  4  Avg. Training Loss: 0.0326\n",
            " -- Epoch  5  Avg. Training Loss: 0.0313\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0294\n",
            " -- Epoch  8  Avg. Training Loss: 0.0287\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0276\n",
            "0:00:13.790116\n",
            " -- Epoch  1  Avg. Training Loss: 0.0378\n",
            " -- Epoch  2  Avg. Training Loss: 0.0332\n",
            " -- Epoch  3  Avg. Training Loss: 0.0309\n",
            " -- Epoch  4  Avg. Training Loss: 0.0295\n",
            " -- Epoch  5  Avg. Training Loss: 0.0284\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0264\n",
            " -- Epoch  9  Avg. Training Loss: 0.0260\n",
            " -- Epoch 10  Avg. Training Loss: 0.0256\n",
            "0:01:07.940494\n",
            " -- Epoch  1  Avg. Training Loss: 0.0489\n",
            " -- Epoch  2  Avg. Training Loss: 0.0423\n",
            " -- Epoch  3  Avg. Training Loss: 0.0392\n",
            " -- Epoch  4  Avg. Training Loss: 0.0372\n",
            " -- Epoch  5  Avg. Training Loss: 0.0358\n",
            " -- Epoch  6  Avg. Training Loss: 0.0348\n",
            " -- Epoch  7  Avg. Training Loss: 0.0339\n",
            " -- Epoch  8  Avg. Training Loss: 0.0332\n",
            " -- Epoch  9  Avg. Training Loss: 0.0327\n",
            " -- Epoch 10  Avg. Training Loss: 0.0321\n",
            "0:00:06.740168\n",
            " -- Epoch  1  Avg. Training Loss: 0.0710\n",
            " -- Epoch  2  Avg. Training Loss: 0.0610\n",
            " -- Epoch  3  Avg. Training Loss: 0.0561\n",
            " -- Epoch  4  Avg. Training Loss: 0.0529\n",
            " -- Epoch  5  Avg. Training Loss: 0.0506\n",
            " -- Epoch  6  Avg. Training Loss: 0.0489\n",
            " -- Epoch  7  Avg. Training Loss: 0.0475\n",
            " -- Epoch  8  Avg. Training Loss: 0.0464\n",
            " -- Epoch  9  Avg. Training Loss: 0.0454\n",
            " -- Epoch 10  Avg. Training Loss: 0.0445\n",
            "0:00:08.171349\n",
            " -- Epoch  1  Avg. Training Loss: 0.0438\n",
            " -- Epoch  2  Avg. Training Loss: 0.0385\n",
            " -- Epoch  3  Avg. Training Loss: 0.0359\n",
            " -- Epoch  4  Avg. Training Loss: 0.0343\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0321\n",
            " -- Epoch  7  Avg. Training Loss: 0.0314\n",
            " -- Epoch  8  Avg. Training Loss: 0.0308\n",
            " -- Epoch  9  Avg. Training Loss: 0.0303\n",
            " -- Epoch 10  Avg. Training Loss: 0.0298\n",
            "0:00:09.249328\n",
            " -- Epoch  1  Avg. Training Loss: 0.0453\n",
            " -- Epoch  2  Avg. Training Loss: 0.0397\n",
            " -- Epoch  3  Avg. Training Loss: 0.0369\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0337\n",
            " -- Epoch  6  Avg. Training Loss: 0.0327\n",
            " -- Epoch  7  Avg. Training Loss: 0.0318\n",
            " -- Epoch  8  Avg. Training Loss: 0.0311\n",
            " -- Epoch  9  Avg. Training Loss: 0.0305\n",
            " -- Epoch 10  Avg. Training Loss: 0.0300\n",
            "0:00:09.950802\n",
            " -- Epoch  1  Avg. Training Loss: 0.0436\n",
            " -- Epoch  2  Avg. Training Loss: 0.0384\n",
            " -- Epoch  3  Avg. Training Loss: 0.0358\n",
            " -- Epoch  4  Avg. Training Loss: 0.0341\n",
            " -- Epoch  5  Avg. Training Loss: 0.0328\n",
            " -- Epoch  6  Avg. Training Loss: 0.0319\n",
            " -- Epoch  7  Avg. Training Loss: 0.0311\n",
            " -- Epoch  8  Avg. Training Loss: 0.0305\n",
            " -- Epoch  9  Avg. Training Loss: 0.0300\n",
            " -- Epoch 10  Avg. Training Loss: 0.0295\n",
            "0:00:07.998239\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:06.261562\n",
            " -- Epoch  1  Avg. Training Loss: 0.0470\n",
            " -- Epoch  2  Avg. Training Loss: 0.0409\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0361\n",
            " -- Epoch  5  Avg. Training Loss: 0.0347\n",
            " -- Epoch  6  Avg. Training Loss: 0.0337\n",
            " -- Epoch  7  Avg. Training Loss: 0.0328\n",
            " -- Epoch  8  Avg. Training Loss: 0.0321\n",
            " -- Epoch  9  Avg. Training Loss: 0.0315\n",
            " -- Epoch 10  Avg. Training Loss: 0.0309\n",
            "0:00:06.520248\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:07.203669\n",
            " -- Epoch  1  Avg. Training Loss: 0.1062\n",
            " -- Epoch  2  Avg. Training Loss: 0.0855\n",
            " -- Epoch  3  Avg. Training Loss: 0.0763\n",
            " -- Epoch  4  Avg. Training Loss: 0.0707\n",
            " -- Epoch  5  Avg. Training Loss: 0.0667\n",
            " -- Epoch  6  Avg. Training Loss: 0.0638\n",
            " -- Epoch  7  Avg. Training Loss: 0.0615\n",
            " -- Epoch  8  Avg. Training Loss: 0.0596\n",
            " -- Epoch  9  Avg. Training Loss: 0.0580\n",
            " -- Epoch 10  Avg. Training Loss: 0.0566\n",
            "0:00:06.649568\n",
            " -- Epoch  1  Avg. Training Loss: 0.0474\n",
            " -- Epoch  2  Avg. Training Loss: 0.0417\n",
            " -- Epoch  3  Avg. Training Loss: 0.0388\n",
            " -- Epoch  4  Avg. Training Loss: 0.0370\n",
            " -- Epoch  5  Avg. Training Loss: 0.0357\n",
            " -- Epoch  6  Avg. Training Loss: 0.0347\n",
            " -- Epoch  7  Avg. Training Loss: 0.0338\n",
            " -- Epoch  8  Avg. Training Loss: 0.0331\n",
            " -- Epoch  9  Avg. Training Loss: 0.0325\n",
            " -- Epoch 10  Avg. Training Loss: 0.0320\n",
            "0:00:11.622233\n",
            " -- Epoch  1  Avg. Training Loss: 0.0402\n",
            " -- Epoch  2  Avg. Training Loss: 0.0356\n",
            " -- Epoch  3  Avg. Training Loss: 0.0333\n",
            " -- Epoch  4  Avg. Training Loss: 0.0317\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0297\n",
            " -- Epoch  7  Avg. Training Loss: 0.0290\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0279\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:21.330936\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0416\n",
            " -- Epoch  3  Avg. Training Loss: 0.0386\n",
            " -- Epoch  4  Avg. Training Loss: 0.0367\n",
            " -- Epoch  5  Avg. Training Loss: 0.0353\n",
            " -- Epoch  6  Avg. Training Loss: 0.0343\n",
            " -- Epoch  7  Avg. Training Loss: 0.0334\n",
            " -- Epoch  8  Avg. Training Loss: 0.0327\n",
            " -- Epoch  9  Avg. Training Loss: 0.0320\n",
            " -- Epoch 10  Avg. Training Loss: 0.0315\n",
            "0:00:06.263801\n",
            " -- Epoch  1  Avg. Training Loss: 0.0460\n",
            " -- Epoch  2  Avg. Training Loss: 0.0402\n",
            " -- Epoch  3  Avg. Training Loss: 0.0374\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0343\n",
            " -- Epoch  6  Avg. Training Loss: 0.0332\n",
            " -- Epoch  7  Avg. Training Loss: 0.0324\n",
            " -- Epoch  8  Avg. Training Loss: 0.0317\n",
            " -- Epoch  9  Avg. Training Loss: 0.0311\n",
            " -- Epoch 10  Avg. Training Loss: 0.0306\n",
            "0:00:10.124777\n",
            " -- Epoch  1  Avg. Training Loss: 0.0578\n",
            " -- Epoch  2  Avg. Training Loss: 0.0480\n",
            " -- Epoch  3  Avg. Training Loss: 0.0436\n",
            " -- Epoch  4  Avg. Training Loss: 0.0409\n",
            " -- Epoch  5  Avg. Training Loss: 0.0389\n",
            " -- Epoch  6  Avg. Training Loss: 0.0375\n",
            " -- Epoch  7  Avg. Training Loss: 0.0363\n",
            " -- Epoch  8  Avg. Training Loss: 0.0353\n",
            " -- Epoch  9  Avg. Training Loss: 0.0345\n",
            " -- Epoch 10  Avg. Training Loss: 0.0338\n",
            "0:00:06.717635\n",
            " -- Epoch  1  Avg. Training Loss: 0.0606\n",
            " -- Epoch  2  Avg. Training Loss: 0.0472\n",
            " -- Epoch  3  Avg. Training Loss: 0.0418\n",
            " -- Epoch  4  Avg. Training Loss: 0.0386\n",
            " -- Epoch  5  Avg. Training Loss: 0.0364\n",
            " -- Epoch  6  Avg. Training Loss: 0.0348\n",
            " -- Epoch  7  Avg. Training Loss: 0.0336\n",
            " -- Epoch  8  Avg. Training Loss: 0.0326\n",
            " -- Epoch  9  Avg. Training Loss: 0.0318\n",
            " -- Epoch 10  Avg. Training Loss: 0.0311\n",
            "0:00:07.158939\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0347\n",
            " -- Epoch  4  Avg. Training Loss: 0.0331\n",
            " -- Epoch  5  Avg. Training Loss: 0.0319\n",
            " -- Epoch  6  Avg. Training Loss: 0.0310\n",
            " -- Epoch  7  Avg. Training Loss: 0.0302\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0286\n",
            "0:00:10.125827\n",
            " -- Epoch  1  Avg. Training Loss: 0.0760\n",
            " -- Epoch  2  Avg. Training Loss: 0.0561\n",
            " -- Epoch  3  Avg. Training Loss: 0.0484\n",
            " -- Epoch  4  Avg. Training Loss: 0.0441\n",
            " -- Epoch  5  Avg. Training Loss: 0.0412\n",
            " -- Epoch  6  Avg. Training Loss: 0.0392\n",
            " -- Epoch  7  Avg. Training Loss: 0.0376\n",
            " -- Epoch  8  Avg. Training Loss: 0.0363\n",
            " -- Epoch  9  Avg. Training Loss: 0.0352\n",
            " -- Epoch 10  Avg. Training Loss: 0.0343\n",
            "0:00:06.389759\n",
            " -- Epoch  1  Avg. Training Loss: 0.0416\n",
            " -- Epoch  2  Avg. Training Loss: 0.0369\n",
            " -- Epoch  3  Avg. Training Loss: 0.0345\n",
            " -- Epoch  4  Avg. Training Loss: 0.0328\n",
            " -- Epoch  5  Avg. Training Loss: 0.0316\n",
            " -- Epoch  6  Avg. Training Loss: 0.0307\n",
            " -- Epoch  7  Avg. Training Loss: 0.0300\n",
            " -- Epoch  8  Avg. Training Loss: 0.0293\n",
            " -- Epoch  9  Avg. Training Loss: 0.0288\n",
            " -- Epoch 10  Avg. Training Loss: 0.0283\n",
            "0:00:18.154967\n",
            " -- Epoch  1  Avg. Training Loss: 0.0424\n",
            " -- Epoch  2  Avg. Training Loss: 0.0369\n",
            " -- Epoch  3  Avg. Training Loss: 0.0343\n",
            " -- Epoch  4  Avg. Training Loss: 0.0326\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0305\n",
            " -- Epoch  7  Avg. Training Loss: 0.0298\n",
            " -- Epoch  8  Avg. Training Loss: 0.0292\n",
            " -- Epoch  9  Avg. Training Loss: 0.0287\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:08.023014\n",
            " -- Epoch  1  Avg. Training Loss: 0.0406\n",
            " -- Epoch  2  Avg. Training Loss: 0.0359\n",
            " -- Epoch  3  Avg. Training Loss: 0.0335\n",
            " -- Epoch  4  Avg. Training Loss: 0.0319\n",
            " -- Epoch  5  Avg. Training Loss: 0.0307\n",
            " -- Epoch  6  Avg. Training Loss: 0.0298\n",
            " -- Epoch  7  Avg. Training Loss: 0.0291\n",
            " -- Epoch  8  Avg. Training Loss: 0.0285\n",
            " -- Epoch  9  Avg. Training Loss: 0.0279\n",
            " -- Epoch 10  Avg. Training Loss: 0.0275\n",
            "0:00:18.080623\n",
            " -- Epoch  1  Avg. Training Loss: 0.0443\n",
            " -- Epoch  2  Avg. Training Loss: 0.0388\n",
            " -- Epoch  3  Avg. Training Loss: 0.0361\n",
            " -- Epoch  4  Avg. Training Loss: 0.0344\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0321\n",
            " -- Epoch  7  Avg. Training Loss: 0.0313\n",
            " -- Epoch  8  Avg. Training Loss: 0.0306\n",
            " -- Epoch  9  Avg. Training Loss: 0.0300\n",
            " -- Epoch 10  Avg. Training Loss: 0.0295\n",
            "0:00:07.688685\n",
            " -- Epoch  1  Avg. Training Loss: 0.0425\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0347\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0318\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0302\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0291\n",
            " -- Epoch 10  Avg. Training Loss: 0.0286\n",
            "0:00:10.125514\n",
            " -- Epoch  1  Avg. Training Loss: 0.0431\n",
            " -- Epoch  2  Avg. Training Loss: 0.0380\n",
            " -- Epoch  3  Avg. Training Loss: 0.0355\n",
            " -- Epoch  4  Avg. Training Loss: 0.0338\n",
            " -- Epoch  5  Avg. Training Loss: 0.0326\n",
            " -- Epoch  6  Avg. Training Loss: 0.0316\n",
            " -- Epoch  7  Avg. Training Loss: 0.0308\n",
            " -- Epoch  8  Avg. Training Loss: 0.0301\n",
            " -- Epoch  9  Avg. Training Loss: 0.0295\n",
            " -- Epoch 10  Avg. Training Loss: 0.0290\n",
            "0:00:14.381664\n",
            " -- Epoch  1  Avg. Training Loss: 12.0690\n",
            " -- Epoch  2  Avg. Training Loss: 6.0643\n",
            " -- Epoch  3  Avg. Training Loss: 4.0610\n",
            " -- Epoch  4  Avg. Training Loss: 3.0590\n",
            " -- Epoch  5  Avg. Training Loss: 2.4577\n",
            " -- Epoch  6  Avg. Training Loss: 2.0567\n",
            " -- Epoch  7  Avg. Training Loss: 1.7701\n",
            " -- Epoch  8  Avg. Training Loss: 1.5552\n",
            " -- Epoch  9  Avg. Training Loss: 1.3879\n",
            " -- Epoch 10  Avg. Training Loss: 1.2541\n",
            "0:00:08.341068\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:06.300575\n",
            " -- Epoch  1  Avg. Training Loss: 0.0450\n",
            " -- Epoch  2  Avg. Training Loss: 0.0397\n",
            " -- Epoch  3  Avg. Training Loss: 0.0370\n",
            " -- Epoch  4  Avg. Training Loss: 0.0352\n",
            " -- Epoch  5  Avg. Training Loss: 0.0338\n",
            " -- Epoch  6  Avg. Training Loss: 0.0328\n",
            " -- Epoch  7  Avg. Training Loss: 0.0320\n",
            " -- Epoch  8  Avg. Training Loss: 0.0312\n",
            " -- Epoch  9  Avg. Training Loss: 0.0306\n",
            " -- Epoch 10  Avg. Training Loss: 0.0301\n",
            "0:00:09.318104\n",
            " -- Epoch  1  Avg. Training Loss: 0.0363\n",
            " -- Epoch  2  Avg. Training Loss: 0.0323\n",
            " -- Epoch  3  Avg. Training Loss: 0.0304\n",
            " -- Epoch  4  Avg. Training Loss: 0.0293\n",
            " -- Epoch  5  Avg. Training Loss: 0.0285\n",
            " -- Epoch  6  Avg. Training Loss: 0.0279\n",
            " -- Epoch  7  Avg. Training Loss: 0.0274\n",
            " -- Epoch  8  Avg. Training Loss: 0.0270\n",
            " -- Epoch  9  Avg. Training Loss: 0.0267\n",
            " -- Epoch 10  Avg. Training Loss: 0.0264\n",
            "0:00:21.309976\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:07.083632\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.020054\n",
            " -- Epoch  1  Avg. Training Loss: 0.0533\n",
            " -- Epoch  2  Avg. Training Loss: 0.0464\n",
            " -- Epoch  3  Avg. Training Loss: 0.0431\n",
            " -- Epoch  4  Avg. Training Loss: 0.0409\n",
            " -- Epoch  5  Avg. Training Loss: 0.0394\n",
            " -- Epoch  6  Avg. Training Loss: 0.0382\n",
            " -- Epoch  7  Avg. Training Loss: 0.0372\n",
            " -- Epoch  8  Avg. Training Loss: 0.0364\n",
            " -- Epoch  9  Avg. Training Loss: 0.0356\n",
            " -- Epoch 10  Avg. Training Loss: 0.0350\n",
            "0:00:08.127156\n",
            " -- Epoch  1  Avg. Training Loss: 0.0626\n",
            " -- Epoch  2  Avg. Training Loss: 0.0530\n",
            " -- Epoch  3  Avg. Training Loss: 0.0486\n",
            " -- Epoch  4  Avg. Training Loss: 0.0459\n",
            " -- Epoch  5  Avg. Training Loss: 0.0439\n",
            " -- Epoch  6  Avg. Training Loss: 0.0424\n",
            " -- Epoch  7  Avg. Training Loss: 0.0413\n",
            " -- Epoch  8  Avg. Training Loss: 0.0403\n",
            " -- Epoch  9  Avg. Training Loss: 0.0395\n",
            " -- Epoch 10  Avg. Training Loss: 0.0388\n",
            "0:00:06.108293\n",
            " -- Epoch  1  Avg. Training Loss: 0.0472\n",
            " -- Epoch  2  Avg. Training Loss: 0.0395\n",
            " -- Epoch  3  Avg. Training Loss: 0.0360\n",
            " -- Epoch  4  Avg. Training Loss: 0.0338\n",
            " -- Epoch  5  Avg. Training Loss: 0.0323\n",
            " -- Epoch  6  Avg. Training Loss: 0.0312\n",
            " -- Epoch  7  Avg. Training Loss: 0.0303\n",
            " -- Epoch  8  Avg. Training Loss: 0.0295\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0284\n",
            "0:00:13.092580\n",
            " -- Epoch  1  Avg. Training Loss: 0.0446\n",
            " -- Epoch  2  Avg. Training Loss: 0.0387\n",
            " -- Epoch  3  Avg. Training Loss: 0.0359\n",
            " -- Epoch  4  Avg. Training Loss: 0.0342\n",
            " -- Epoch  5  Avg. Training Loss: 0.0330\n",
            " -- Epoch  6  Avg. Training Loss: 0.0321\n",
            " -- Epoch  7  Avg. Training Loss: 0.0313\n",
            " -- Epoch  8  Avg. Training Loss: 0.0307\n",
            " -- Epoch  9  Avg. Training Loss: 0.0302\n",
            " -- Epoch 10  Avg. Training Loss: 0.0298\n",
            "0:00:06.995532\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:09.960523\n",
            " -- Epoch  1  Avg. Training Loss: 0.0355\n",
            " -- Epoch  2  Avg. Training Loss: 0.0319\n",
            " -- Epoch  3  Avg. Training Loss: 0.0301\n",
            " -- Epoch  4  Avg. Training Loss: 0.0290\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0275\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0265\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0258\n",
            "0:00:42.008544\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:23.022227\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:09.676774\n",
            " -- Epoch  1  Avg. Training Loss: 0.0512\n",
            " -- Epoch  2  Avg. Training Loss: 0.0448\n",
            " -- Epoch  3  Avg. Training Loss: 0.0416\n",
            " -- Epoch  4  Avg. Training Loss: 0.0395\n",
            " -- Epoch  5  Avg. Training Loss: 0.0380\n",
            " -- Epoch  6  Avg. Training Loss: 0.0368\n",
            " -- Epoch  7  Avg. Training Loss: 0.0359\n",
            " -- Epoch  8  Avg. Training Loss: 0.0351\n",
            " -- Epoch  9  Avg. Training Loss: 0.0344\n",
            " -- Epoch 10  Avg. Training Loss: 0.0338\n",
            "0:00:09.417124\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:18.130766\n",
            " -- Epoch  1  Avg. Training Loss: 0.0481\n",
            " -- Epoch  2  Avg. Training Loss: 0.0421\n",
            " -- Epoch  3  Avg. Training Loss: 0.0392\n",
            " -- Epoch  4  Avg. Training Loss: 0.0374\n",
            " -- Epoch  5  Avg. Training Loss: 0.0360\n",
            " -- Epoch  6  Avg. Training Loss: 0.0350\n",
            " -- Epoch  7  Avg. Training Loss: 0.0341\n",
            " -- Epoch  8  Avg. Training Loss: 0.0334\n",
            " -- Epoch  9  Avg. Training Loss: 0.0328\n",
            " -- Epoch 10  Avg. Training Loss: 0.0323\n",
            "0:00:08.199402\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:32.419544\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:07.628522\n",
            " -- Epoch  1  Avg. Training Loss: 0.0490\n",
            " -- Epoch  2  Avg. Training Loss: 0.0427\n",
            " -- Epoch  3  Avg. Training Loss: 0.0396\n",
            " -- Epoch  4  Avg. Training Loss: 0.0376\n",
            " -- Epoch  5  Avg. Training Loss: 0.0361\n",
            " -- Epoch  6  Avg. Training Loss: 0.0350\n",
            " -- Epoch  7  Avg. Training Loss: 0.0341\n",
            " -- Epoch  8  Avg. Training Loss: 0.0333\n",
            " -- Epoch  9  Avg. Training Loss: 0.0327\n",
            " -- Epoch 10  Avg. Training Loss: 0.0321\n",
            "0:00:07.278252\n",
            " -- Epoch  1  Avg. Training Loss: 0.0426\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0336\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0314\n",
            " -- Epoch  7  Avg. Training Loss: 0.0306\n",
            " -- Epoch  8  Avg. Training Loss: 0.0300\n",
            " -- Epoch  9  Avg. Training Loss: 0.0294\n",
            " -- Epoch 10  Avg. Training Loss: 0.0289\n",
            "0:00:15.947992\n",
            " -- Epoch  1  Avg. Training Loss: 0.0654\n",
            " -- Epoch  2  Avg. Training Loss: 0.0497\n",
            " -- Epoch  3  Avg. Training Loss: 0.0434\n",
            " -- Epoch  4  Avg. Training Loss: 0.0399\n",
            " -- Epoch  5  Avg. Training Loss: 0.0375\n",
            " -- Epoch  6  Avg. Training Loss: 0.0358\n",
            " -- Epoch  7  Avg. Training Loss: 0.0345\n",
            " -- Epoch  8  Avg. Training Loss: 0.0334\n",
            " -- Epoch  9  Avg. Training Loss: 0.0325\n",
            " -- Epoch 10  Avg. Training Loss: 0.0318\n",
            "0:00:07.794037\n",
            " -- Epoch  1  Avg. Training Loss: 0.0393\n",
            " -- Epoch  2  Avg. Training Loss: 0.0342\n",
            " -- Epoch  3  Avg. Training Loss: 0.0319\n",
            " -- Epoch  4  Avg. Training Loss: 0.0305\n",
            " -- Epoch  5  Avg. Training Loss: 0.0295\n",
            " -- Epoch  6  Avg. Training Loss: 0.0287\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0268\n",
            "0:00:13.149462\n",
            " -- Epoch  1  Avg. Training Loss: 0.0513\n",
            " -- Epoch  2  Avg. Training Loss: 0.0449\n",
            " -- Epoch  3  Avg. Training Loss: 0.0417\n",
            " -- Epoch  4  Avg. Training Loss: 0.0397\n",
            " -- Epoch  5  Avg. Training Loss: 0.0382\n",
            " -- Epoch  6  Avg. Training Loss: 0.0370\n",
            " -- Epoch  7  Avg. Training Loss: 0.0361\n",
            " -- Epoch  8  Avg. Training Loss: 0.0353\n",
            " -- Epoch  9  Avg. Training Loss: 0.0346\n",
            " -- Epoch 10  Avg. Training Loss: 0.0340\n",
            "0:00:07.850290\n",
            " -- Epoch  1  Avg. Training Loss: 0.0365\n",
            " -- Epoch  2  Avg. Training Loss: 0.0325\n",
            " -- Epoch  3  Avg. Training Loss: 0.0305\n",
            " -- Epoch  4  Avg. Training Loss: 0.0292\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0266\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0259\n",
            "0:00:29.635133\n",
            " -- Epoch  1  Avg. Training Loss: 0.0566\n",
            " -- Epoch  2  Avg. Training Loss: 0.0486\n",
            " -- Epoch  3  Avg. Training Loss: 0.0448\n",
            " -- Epoch  4  Avg. Training Loss: 0.0424\n",
            " -- Epoch  5  Avg. Training Loss: 0.0407\n",
            " -- Epoch  6  Avg. Training Loss: 0.0395\n",
            " -- Epoch  7  Avg. Training Loss: 0.0384\n",
            " -- Epoch  8  Avg. Training Loss: 0.0376\n",
            " -- Epoch  9  Avg. Training Loss: 0.0368\n",
            " -- Epoch 10  Avg. Training Loss: 0.0362\n",
            "0:00:22.785198\n",
            " -- Epoch  1  Avg. Training Loss: 0.0447\n",
            " -- Epoch  2  Avg. Training Loss: 0.0386\n",
            " -- Epoch  3  Avg. Training Loss: 0.0357\n",
            " -- Epoch  4  Avg. Training Loss: 0.0340\n",
            " -- Epoch  5  Avg. Training Loss: 0.0327\n",
            " -- Epoch  6  Avg. Training Loss: 0.0318\n",
            " -- Epoch  7  Avg. Training Loss: 0.0310\n",
            " -- Epoch  8  Avg. Training Loss: 0.0304\n",
            " -- Epoch  9  Avg. Training Loss: 0.0299\n",
            " -- Epoch 10  Avg. Training Loss: 0.0295\n",
            "0:00:06.593492\n",
            " -- Epoch  1  Avg. Training Loss: 0.0481\n",
            " -- Epoch  2  Avg. Training Loss: 0.0423\n",
            " -- Epoch  3  Avg. Training Loss: 0.0394\n",
            " -- Epoch  4  Avg. Training Loss: 0.0375\n",
            " -- Epoch  5  Avg. Training Loss: 0.0361\n",
            " -- Epoch  6  Avg. Training Loss: 0.0350\n",
            " -- Epoch  7  Avg. Training Loss: 0.0341\n",
            " -- Epoch  8  Avg. Training Loss: 0.0333\n",
            " -- Epoch  9  Avg. Training Loss: 0.0327\n",
            " -- Epoch 10  Avg. Training Loss: 0.0321\n",
            "0:00:08.470896\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:06.359689\n",
            " -- Epoch  1  Avg. Training Loss: 0.0357\n",
            " -- Epoch  2  Avg. Training Loss: 0.0320\n",
            " -- Epoch  3  Avg. Training Loss: 0.0302\n",
            " -- Epoch  4  Avg. Training Loss: 0.0291\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0267\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:59.386882\n",
            " -- Epoch  1  Avg. Training Loss: 0.0533\n",
            " -- Epoch  2  Avg. Training Loss: 0.0465\n",
            " -- Epoch  3  Avg. Training Loss: 0.0432\n",
            " -- Epoch  4  Avg. Training Loss: 0.0411\n",
            " -- Epoch  5  Avg. Training Loss: 0.0395\n",
            " -- Epoch  6  Avg. Training Loss: 0.0383\n",
            " -- Epoch  7  Avg. Training Loss: 0.0373\n",
            " -- Epoch  8  Avg. Training Loss: 0.0365\n",
            " -- Epoch  9  Avg. Training Loss: 0.0358\n",
            " -- Epoch 10  Avg. Training Loss: 0.0352\n",
            "0:00:06.951202\n",
            " -- Epoch  1  Avg. Training Loss: 0.0379\n",
            " -- Epoch  2  Avg. Training Loss: 0.0335\n",
            " -- Epoch  3  Avg. Training Loss: 0.0314\n",
            " -- Epoch  4  Avg. Training Loss: 0.0300\n",
            " -- Epoch  5  Avg. Training Loss: 0.0291\n",
            " -- Epoch  6  Avg. Training Loss: 0.0283\n",
            " -- Epoch  7  Avg. Training Loss: 0.0277\n",
            " -- Epoch  8  Avg. Training Loss: 0.0272\n",
            " -- Epoch  9  Avg. Training Loss: 0.0268\n",
            " -- Epoch 10  Avg. Training Loss: 0.0264\n",
            "0:00:17.207399\n",
            " -- Epoch  1  Avg. Training Loss: 0.0436\n",
            " -- Epoch  2  Avg. Training Loss: 0.0386\n",
            " -- Epoch  3  Avg. Training Loss: 0.0360\n",
            " -- Epoch  4  Avg. Training Loss: 0.0344\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0322\n",
            " -- Epoch  7  Avg. Training Loss: 0.0314\n",
            " -- Epoch  8  Avg. Training Loss: 0.0307\n",
            " -- Epoch  9  Avg. Training Loss: 0.0301\n",
            " -- Epoch 10  Avg. Training Loss: 0.0296\n",
            "0:00:23.621630\n",
            " -- Epoch  1  Avg. Training Loss: 0.0458\n",
            " -- Epoch  2  Avg. Training Loss: 0.0404\n",
            " -- Epoch  3  Avg. Training Loss: 0.0376\n",
            " -- Epoch  4  Avg. Training Loss: 0.0358\n",
            " -- Epoch  5  Avg. Training Loss: 0.0345\n",
            " -- Epoch  6  Avg. Training Loss: 0.0335\n",
            " -- Epoch  7  Avg. Training Loss: 0.0327\n",
            " -- Epoch  8  Avg. Training Loss: 0.0320\n",
            " -- Epoch  9  Avg. Training Loss: 0.0314\n",
            " -- Epoch 10  Avg. Training Loss: 0.0309\n",
            "0:00:07.020161\n",
            " -- Epoch  1  Avg. Training Loss: 0.0355\n",
            " -- Epoch  2  Avg. Training Loss: 0.0319\n",
            " -- Epoch  3  Avg. Training Loss: 0.0301\n",
            " -- Epoch  4  Avg. Training Loss: 0.0290\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0275\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0265\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0258\n",
            "0:00:42.360898\n",
            " -- Epoch  1  Avg. Training Loss: 0.0357\n",
            " -- Epoch  2  Avg. Training Loss: 0.0320\n",
            " -- Epoch  3  Avg. Training Loss: 0.0302\n",
            " -- Epoch  4  Avg. Training Loss: 0.0291\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0267\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:57.988885\n",
            " -- Epoch  1  Avg. Training Loss: 0.0451\n",
            " -- Epoch  2  Avg. Training Loss: 0.0397\n",
            " -- Epoch  3  Avg. Training Loss: 0.0370\n",
            " -- Epoch  4  Avg. Training Loss: 0.0352\n",
            " -- Epoch  5  Avg. Training Loss: 0.0339\n",
            " -- Epoch  6  Avg. Training Loss: 0.0330\n",
            " -- Epoch  7  Avg. Training Loss: 0.0322\n",
            " -- Epoch  8  Avg. Training Loss: 0.0315\n",
            " -- Epoch  9  Avg. Training Loss: 0.0309\n",
            " -- Epoch 10  Avg. Training Loss: 0.0304\n",
            "0:00:17.739418\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:22.613703\n",
            " -- Epoch  1  Avg. Training Loss: 0.0430\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0352\n",
            " -- Epoch  4  Avg. Training Loss: 0.0335\n",
            " -- Epoch  5  Avg. Training Loss: 0.0323\n",
            " -- Epoch  6  Avg. Training Loss: 0.0313\n",
            " -- Epoch  7  Avg. Training Loss: 0.0306\n",
            " -- Epoch  8  Avg. Training Loss: 0.0299\n",
            " -- Epoch  9  Avg. Training Loss: 0.0294\n",
            " -- Epoch 10  Avg. Training Loss: 0.0289\n",
            "0:00:07.583694\n",
            " -- Epoch  1  Avg. Training Loss: 0.0424\n",
            " -- Epoch  2  Avg. Training Loss: 0.0374\n",
            " -- Epoch  3  Avg. Training Loss: 0.0349\n",
            " -- Epoch  4  Avg. Training Loss: 0.0333\n",
            " -- Epoch  5  Avg. Training Loss: 0.0321\n",
            " -- Epoch  6  Avg. Training Loss: 0.0312\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0299\n",
            " -- Epoch  9  Avg. Training Loss: 0.0294\n",
            " -- Epoch 10  Avg. Training Loss: 0.0290\n",
            "0:00:09.507119\n",
            " -- Epoch  1  Avg. Training Loss: 0.0343\n",
            " -- Epoch  2  Avg. Training Loss: 0.0307\n",
            " -- Epoch  3  Avg. Training Loss: 0.0289\n",
            " -- Epoch  4  Avg. Training Loss: 0.0278\n",
            " -- Epoch  5  Avg. Training Loss: 0.0270\n",
            " -- Epoch  6  Avg. Training Loss: 0.0264\n",
            " -- Epoch  7  Avg. Training Loss: 0.0259\n",
            " -- Epoch  8  Avg. Training Loss: 0.0254\n",
            " -- Epoch  9  Avg. Training Loss: 0.0251\n",
            " -- Epoch 10  Avg. Training Loss: 0.0247\n",
            "0:00:58.423817\n",
            " -- Epoch  1  Avg. Training Loss: 0.0508\n",
            " -- Epoch  2  Avg. Training Loss: 0.0440\n",
            " -- Epoch  3  Avg. Training Loss: 0.0407\n",
            " -- Epoch  4  Avg. Training Loss: 0.0387\n",
            " -- Epoch  5  Avg. Training Loss: 0.0372\n",
            " -- Epoch  6  Avg. Training Loss: 0.0361\n",
            " -- Epoch  7  Avg. Training Loss: 0.0352\n",
            " -- Epoch  8  Avg. Training Loss: 0.0344\n",
            " -- Epoch  9  Avg. Training Loss: 0.0338\n",
            " -- Epoch 10  Avg. Training Loss: 0.0332\n",
            "0:00:08.087326\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:29.750771\n",
            " -- Epoch  1  Avg. Training Loss: 0.0393\n",
            " -- Epoch  2  Avg. Training Loss: 0.0342\n",
            " -- Epoch  3  Avg. Training Loss: 0.0319\n",
            " -- Epoch  4  Avg. Training Loss: 0.0305\n",
            " -- Epoch  5  Avg. Training Loss: 0.0295\n",
            " -- Epoch  6  Avg. Training Loss: 0.0287\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0268\n",
            "0:00:13.466858\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:29.166340\n",
            " -- Epoch  1  Avg. Training Loss: 0.0426\n",
            " -- Epoch  2  Avg. Training Loss: 0.0367\n",
            " -- Epoch  3  Avg. Training Loss: 0.0338\n",
            " -- Epoch  4  Avg. Training Loss: 0.0320\n",
            " -- Epoch  5  Avg. Training Loss: 0.0307\n",
            " -- Epoch  6  Avg. Training Loss: 0.0297\n",
            " -- Epoch  7  Avg. Training Loss: 0.0290\n",
            " -- Epoch  8  Avg. Training Loss: 0.0283\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0273\n",
            "0:00:24.240244\n",
            " -- Epoch  1  Avg. Training Loss: 0.0450\n",
            " -- Epoch  2  Avg. Training Loss: 0.0396\n",
            " -- Epoch  3  Avg. Training Loss: 0.0369\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0338\n",
            " -- Epoch  6  Avg. Training Loss: 0.0327\n",
            " -- Epoch  7  Avg. Training Loss: 0.0319\n",
            " -- Epoch  8  Avg. Training Loss: 0.0312\n",
            " -- Epoch  9  Avg. Training Loss: 0.0306\n",
            " -- Epoch 10  Avg. Training Loss: 0.0300\n",
            "0:00:10.052092\n",
            " -- Epoch  1  Avg. Training Loss: 0.0472\n",
            " -- Epoch  2  Avg. Training Loss: 0.0395\n",
            " -- Epoch  3  Avg. Training Loss: 0.0360\n",
            " -- Epoch  4  Avg. Training Loss: 0.0338\n",
            " -- Epoch  5  Avg. Training Loss: 0.0323\n",
            " -- Epoch  6  Avg. Training Loss: 0.0312\n",
            " -- Epoch  7  Avg. Training Loss: 0.0303\n",
            " -- Epoch  8  Avg. Training Loss: 0.0295\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0284\n",
            "0:00:13.519356\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:33.098672\n",
            " -- Epoch  1  Avg. Training Loss: 0.0426\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0336\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0314\n",
            " -- Epoch  7  Avg. Training Loss: 0.0306\n",
            " -- Epoch  8  Avg. Training Loss: 0.0300\n",
            " -- Epoch  9  Avg. Training Loss: 0.0294\n",
            " -- Epoch 10  Avg. Training Loss: 0.0289\n",
            "0:00:15.559815\n",
            " -- Epoch  1  Avg. Training Loss: 0.0442\n",
            " -- Epoch  2  Avg. Training Loss: 0.0390\n",
            " -- Epoch  3  Avg. Training Loss: 0.0363\n",
            " -- Epoch  4  Avg. Training Loss: 0.0346\n",
            " -- Epoch  5  Avg. Training Loss: 0.0333\n",
            " -- Epoch  6  Avg. Training Loss: 0.0323\n",
            " -- Epoch  7  Avg. Training Loss: 0.0315\n",
            " -- Epoch  8  Avg. Training Loss: 0.0308\n",
            " -- Epoch  9  Avg. Training Loss: 0.0302\n",
            " -- Epoch 10  Avg. Training Loss: 0.0297\n",
            "0:00:13.691151\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:17.054270\n",
            " -- Epoch  1  Avg. Training Loss: 0.0365\n",
            " -- Epoch  2  Avg. Training Loss: 0.0325\n",
            " -- Epoch  3  Avg. Training Loss: 0.0305\n",
            " -- Epoch  4  Avg. Training Loss: 0.0292\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0266\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0259\n",
            "0:00:29.988651\n",
            " -- Epoch  1  Avg. Training Loss: 0.0357\n",
            " -- Epoch  2  Avg. Training Loss: 0.0320\n",
            " -- Epoch  3  Avg. Training Loss: 0.0302\n",
            " -- Epoch  4  Avg. Training Loss: 0.0291\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0267\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:56.849256\n",
            " -- Epoch  1  Avg. Training Loss: 0.0416\n",
            " -- Epoch  2  Avg. Training Loss: 0.0369\n",
            " -- Epoch  3  Avg. Training Loss: 0.0345\n",
            " -- Epoch  4  Avg. Training Loss: 0.0328\n",
            " -- Epoch  5  Avg. Training Loss: 0.0316\n",
            " -- Epoch  6  Avg. Training Loss: 0.0307\n",
            " -- Epoch  7  Avg. Training Loss: 0.0300\n",
            " -- Epoch  8  Avg. Training Loss: 0.0293\n",
            " -- Epoch  9  Avg. Training Loss: 0.0288\n",
            " -- Epoch 10  Avg. Training Loss: 0.0283\n",
            "0:00:18.588991\n",
            " -- Epoch  1  Avg. Training Loss: 0.0422\n",
            " -- Epoch  2  Avg. Training Loss: 0.0372\n",
            " -- Epoch  3  Avg. Training Loss: 0.0346\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0318\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0302\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0286\n",
            "0:00:12.320053\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:17.429236\n",
            " -- Epoch  1  Avg. Training Loss: 0.0566\n",
            " -- Epoch  2  Avg. Training Loss: 0.0486\n",
            " -- Epoch  3  Avg. Training Loss: 0.0448\n",
            " -- Epoch  4  Avg. Training Loss: 0.0424\n",
            " -- Epoch  5  Avg. Training Loss: 0.0407\n",
            " -- Epoch  6  Avg. Training Loss: 0.0395\n",
            " -- Epoch  7  Avg. Training Loss: 0.0384\n",
            " -- Epoch  8  Avg. Training Loss: 0.0376\n",
            " -- Epoch  9  Avg. Training Loss: 0.0368\n",
            " -- Epoch 10  Avg. Training Loss: 0.0362\n",
            "0:00:22.373424\n",
            " -- Epoch  1  Avg. Training Loss: 0.0460\n",
            " -- Epoch  2  Avg. Training Loss: 0.0402\n",
            " -- Epoch  3  Avg. Training Loss: 0.0374\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0343\n",
            " -- Epoch  6  Avg. Training Loss: 0.0332\n",
            " -- Epoch  7  Avg. Training Loss: 0.0324\n",
            " -- Epoch  8  Avg. Training Loss: 0.0317\n",
            " -- Epoch  9  Avg. Training Loss: 0.0311\n",
            " -- Epoch 10  Avg. Training Loss: 0.0306\n",
            "0:00:09.835816\n",
            " -- Epoch  1  Avg. Training Loss: 0.0379\n",
            " -- Epoch  2  Avg. Training Loss: 0.0335\n",
            " -- Epoch  3  Avg. Training Loss: 0.0314\n",
            " -- Epoch  4  Avg. Training Loss: 0.0300\n",
            " -- Epoch  5  Avg. Training Loss: 0.0291\n",
            " -- Epoch  6  Avg. Training Loss: 0.0283\n",
            " -- Epoch  7  Avg. Training Loss: 0.0277\n",
            " -- Epoch  8  Avg. Training Loss: 0.0272\n",
            " -- Epoch  9  Avg. Training Loss: 0.0268\n",
            " -- Epoch 10  Avg. Training Loss: 0.0264\n",
            "0:00:17.838630\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.697003\n",
            " -- Epoch  1  Avg. Training Loss: 0.0357\n",
            " -- Epoch  2  Avg. Training Loss: 0.0320\n",
            " -- Epoch  3  Avg. Training Loss: 0.0302\n",
            " -- Epoch  4  Avg. Training Loss: 0.0291\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0267\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:55.484415\n",
            " -- Epoch  1  Avg. Training Loss: 0.0511\n",
            " -- Epoch  2  Avg. Training Loss: 0.0446\n",
            " -- Epoch  3  Avg. Training Loss: 0.0414\n",
            " -- Epoch  4  Avg. Training Loss: 0.0393\n",
            " -- Epoch  5  Avg. Training Loss: 0.0378\n",
            " -- Epoch  6  Avg. Training Loss: 0.0367\n",
            " -- Epoch  7  Avg. Training Loss: 0.0357\n",
            " -- Epoch  8  Avg. Training Loss: 0.0349\n",
            " -- Epoch  9  Avg. Training Loss: 0.0342\n",
            " -- Epoch 10  Avg. Training Loss: 0.0336\n",
            "0:00:06.902271\n",
            " -- Epoch  1  Avg. Training Loss: 0.0450\n",
            " -- Epoch  2  Avg. Training Loss: 0.0397\n",
            " -- Epoch  3  Avg. Training Loss: 0.0370\n",
            " -- Epoch  4  Avg. Training Loss: 0.0352\n",
            " -- Epoch  5  Avg. Training Loss: 0.0338\n",
            " -- Epoch  6  Avg. Training Loss: 0.0328\n",
            " -- Epoch  7  Avg. Training Loss: 0.0320\n",
            " -- Epoch  8  Avg. Training Loss: 0.0312\n",
            " -- Epoch  9  Avg. Training Loss: 0.0306\n",
            " -- Epoch 10  Avg. Training Loss: 0.0301\n",
            "0:00:09.620024\n",
            " -- Epoch  1  Avg. Training Loss: 0.0446\n",
            " -- Epoch  2  Avg. Training Loss: 0.0387\n",
            " -- Epoch  3  Avg. Training Loss: 0.0359\n",
            " -- Epoch  4  Avg. Training Loss: 0.0342\n",
            " -- Epoch  5  Avg. Training Loss: 0.0330\n",
            " -- Epoch  6  Avg. Training Loss: 0.0321\n",
            " -- Epoch  7  Avg. Training Loss: 0.0313\n",
            " -- Epoch  8  Avg. Training Loss: 0.0307\n",
            " -- Epoch  9  Avg. Training Loss: 0.0302\n",
            " -- Epoch 10  Avg. Training Loss: 0.0298\n",
            "0:00:06.732254\n",
            " -- Epoch  1  Avg. Training Loss: 0.0654\n",
            " -- Epoch  2  Avg. Training Loss: 0.0497\n",
            " -- Epoch  3  Avg. Training Loss: 0.0434\n",
            " -- Epoch  4  Avg. Training Loss: 0.0399\n",
            " -- Epoch  5  Avg. Training Loss: 0.0375\n",
            " -- Epoch  6  Avg. Training Loss: 0.0358\n",
            " -- Epoch  7  Avg. Training Loss: 0.0345\n",
            " -- Epoch  8  Avg. Training Loss: 0.0334\n",
            " -- Epoch  9  Avg. Training Loss: 0.0325\n",
            " -- Epoch 10  Avg. Training Loss: 0.0318\n",
            "0:00:07.686699\n",
            " -- Epoch  1  Avg. Training Loss: 0.0433\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0343\n",
            " -- Epoch  4  Avg. Training Loss: 0.0325\n",
            " -- Epoch  5  Avg. Training Loss: 0.0311\n",
            " -- Epoch  6  Avg. Training Loss: 0.0301\n",
            " -- Epoch  7  Avg. Training Loss: 0.0293\n",
            " -- Epoch  8  Avg. Training Loss: 0.0286\n",
            " -- Epoch  9  Avg. Training Loss: 0.0280\n",
            " -- Epoch 10  Avg. Training Loss: 0.0275\n",
            "0:00:21.368289\n",
            " -- Epoch  1  Avg. Training Loss: 0.0417\n",
            " -- Epoch  2  Avg. Training Loss: 0.0363\n",
            " -- Epoch  3  Avg. Training Loss: 0.0338\n",
            " -- Epoch  4  Avg. Training Loss: 0.0322\n",
            " -- Epoch  5  Avg. Training Loss: 0.0311\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0296\n",
            " -- Epoch  8  Avg. Training Loss: 0.0290\n",
            " -- Epoch  9  Avg. Training Loss: 0.0286\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:08.580981\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0348\n",
            " -- Epoch  4  Avg. Training Loss: 0.0332\n",
            " -- Epoch  5  Avg. Training Loss: 0.0320\n",
            " -- Epoch  6  Avg. Training Loss: 0.0311\n",
            " -- Epoch  7  Avg. Training Loss: 0.0304\n",
            " -- Epoch  8  Avg. Training Loss: 0.0297\n",
            " -- Epoch  9  Avg. Training Loss: 0.0292\n",
            " -- Epoch 10  Avg. Training Loss: 0.0287\n",
            "0:00:15.209957\n",
            " -- Epoch  1  Avg. Training Loss: 0.1040\n",
            " -- Epoch  2  Avg. Training Loss: 0.0837\n",
            " -- Epoch  3  Avg. Training Loss: 0.0748\n",
            " -- Epoch  4  Avg. Training Loss: 0.0694\n",
            " -- Epoch  5  Avg. Training Loss: 0.0656\n",
            " -- Epoch  6  Avg. Training Loss: 0.0628\n",
            " -- Epoch  7  Avg. Training Loss: 0.0605\n",
            " -- Epoch  8  Avg. Training Loss: 0.0587\n",
            " -- Epoch  9  Avg. Training Loss: 0.0572\n",
            " -- Epoch 10  Avg. Training Loss: 0.0559\n",
            "0:00:06.137434\n",
            " -- Epoch  1  Avg. Training Loss: 0.0443\n",
            " -- Epoch  2  Avg. Training Loss: 0.0383\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0335\n",
            " -- Epoch  5  Avg. Training Loss: 0.0321\n",
            " -- Epoch  6  Avg. Training Loss: 0.0311\n",
            " -- Epoch  7  Avg. Training Loss: 0.0303\n",
            " -- Epoch  8  Avg. Training Loss: 0.0297\n",
            " -- Epoch  9  Avg. Training Loss: 0.0291\n",
            " -- Epoch 10  Avg. Training Loss: 0.0286\n",
            "0:00:08.874064\n",
            " -- Epoch  1  Avg. Training Loss: 0.0440\n",
            " -- Epoch  2  Avg. Training Loss: 0.0387\n",
            " -- Epoch  3  Avg. Training Loss: 0.0361\n",
            " -- Epoch  4  Avg. Training Loss: 0.0344\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0322\n",
            " -- Epoch  7  Avg. Training Loss: 0.0314\n",
            " -- Epoch  8  Avg. Training Loss: 0.0307\n",
            " -- Epoch  9  Avg. Training Loss: 0.0302\n",
            " -- Epoch 10  Avg. Training Loss: 0.0297\n",
            "0:00:06.982715\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:31.819099\n",
            " -- Epoch  1  Avg. Training Loss: 0.0425\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0347\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0318\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0302\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0291\n",
            " -- Epoch 10  Avg. Training Loss: 0.0286\n",
            "0:00:09.929948\n",
            " -- Epoch  1  Avg. Training Loss: 0.0402\n",
            " -- Epoch  2  Avg. Training Loss: 0.0356\n",
            " -- Epoch  3  Avg. Training Loss: 0.0333\n",
            " -- Epoch  4  Avg. Training Loss: 0.0317\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0297\n",
            " -- Epoch  7  Avg. Training Loss: 0.0290\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0279\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:21.749499\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.458076\n",
            " -- Epoch  1  Avg. Training Loss: 0.0421\n",
            " -- Epoch  2  Avg. Training Loss: 0.0372\n",
            " -- Epoch  3  Avg. Training Loss: 0.0346\n",
            " -- Epoch  4  Avg. Training Loss: 0.0329\n",
            " -- Epoch  5  Avg. Training Loss: 0.0317\n",
            " -- Epoch  6  Avg. Training Loss: 0.0308\n",
            " -- Epoch  7  Avg. Training Loss: 0.0300\n",
            " -- Epoch  8  Avg. Training Loss: 0.0294\n",
            " -- Epoch  9  Avg. Training Loss: 0.0288\n",
            " -- Epoch 10  Avg. Training Loss: 0.0284\n",
            "0:00:08.448314\n",
            " -- Epoch  1  Avg. Training Loss: 0.0401\n",
            " -- Epoch  2  Avg. Training Loss: 0.0351\n",
            " -- Epoch  3  Avg. Training Loss: 0.0327\n",
            " -- Epoch  4  Avg. Training Loss: 0.0312\n",
            " -- Epoch  5  Avg. Training Loss: 0.0301\n",
            " -- Epoch  6  Avg. Training Loss: 0.0293\n",
            " -- Epoch  7  Avg. Training Loss: 0.0286\n",
            " -- Epoch  8  Avg. Training Loss: 0.0281\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:14.382615\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:01:08.203263\n",
            " -- Epoch  1  Avg. Training Loss: 0.0373\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0299\n",
            " -- Epoch  5  Avg. Training Loss: 0.0289\n",
            " -- Epoch  6  Avg. Training Loss: 0.0281\n",
            " -- Epoch  7  Avg. Training Loss: 0.0275\n",
            " -- Epoch  8  Avg. Training Loss: 0.0269\n",
            " -- Epoch  9  Avg. Training Loss: 0.0265\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:32.894533\n",
            " -- Epoch  1  Avg. Training Loss: 0.0606\n",
            " -- Epoch  2  Avg. Training Loss: 0.0472\n",
            " -- Epoch  3  Avg. Training Loss: 0.0418\n",
            " -- Epoch  4  Avg. Training Loss: 0.0386\n",
            " -- Epoch  5  Avg. Training Loss: 0.0364\n",
            " -- Epoch  6  Avg. Training Loss: 0.0348\n",
            " -- Epoch  7  Avg. Training Loss: 0.0336\n",
            " -- Epoch  8  Avg. Training Loss: 0.0326\n",
            " -- Epoch  9  Avg. Training Loss: 0.0318\n",
            " -- Epoch 10  Avg. Training Loss: 0.0311\n",
            "0:00:06.759495\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0347\n",
            " -- Epoch  4  Avg. Training Loss: 0.0331\n",
            " -- Epoch  5  Avg. Training Loss: 0.0319\n",
            " -- Epoch  6  Avg. Training Loss: 0.0310\n",
            " -- Epoch  7  Avg. Training Loss: 0.0302\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0286\n",
            "0:00:09.454160\n",
            "[==                  ] 10%0:36:13.216477\n",
            "Generation #0\n",
            " -- Epoch  1  Avg. Training Loss: 0.0406\n",
            " -- Epoch  2  Avg. Training Loss: 0.0359\n",
            " -- Epoch  3  Avg. Training Loss: 0.0335\n",
            " -- Epoch  4  Avg. Training Loss: 0.0319\n",
            " -- Epoch  5  Avg. Training Loss: 0.0307\n",
            " -- Epoch  6  Avg. Training Loss: 0.0298\n",
            " -- Epoch  7  Avg. Training Loss: 0.0291\n",
            " -- Epoch  8  Avg. Training Loss: 0.0285\n",
            " -- Epoch  9  Avg. Training Loss: 0.0279\n",
            " -- Epoch 10  Avg. Training Loss: 0.0275\n",
            "0:00:18.933599\n",
            " -- Epoch  1  Avg. Training Loss: 0.0385\n",
            " -- Epoch  2  Avg. Training Loss: 0.0343\n",
            " -- Epoch  3  Avg. Training Loss: 0.0321\n",
            " -- Epoch  4  Avg. Training Loss: 0.0307\n",
            " -- Epoch  5  Avg. Training Loss: 0.0296\n",
            " -- Epoch  6  Avg. Training Loss: 0.0287\n",
            " -- Epoch  7  Avg. Training Loss: 0.0280\n",
            " -- Epoch  8  Avg. Training Loss: 0.0274\n",
            " -- Epoch  9  Avg. Training Loss: 0.0269\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:00:32.817826\n",
            " -- Epoch  1  Avg. Training Loss: 0.0551\n",
            " -- Epoch  2  Avg. Training Loss: 0.0421\n",
            " -- Epoch  3  Avg. Training Loss: 0.0370\n",
            " -- Epoch  4  Avg. Training Loss: 0.0342\n",
            " -- Epoch  5  Avg. Training Loss: 0.0323\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0299\n",
            " -- Epoch  8  Avg. Training Loss: 0.0291\n",
            " -- Epoch  9  Avg. Training Loss: 0.0284\n",
            " -- Epoch 10  Avg. Training Loss: 0.0278\n",
            "0:00:30.786762\n",
            " -- Epoch  1  Avg. Training Loss: 0.0398\n",
            " -- Epoch  2  Avg. Training Loss: 0.0349\n",
            " -- Epoch  3  Avg. Training Loss: 0.0325\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0298\n",
            " -- Epoch  6  Avg. Training Loss: 0.0289\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0267\n",
            "0:00:34.305179\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:24.612111\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.443721\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:31.162564\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:29.749351\n",
            " -- Epoch  1  Avg. Training Loss: 0.0379\n",
            " -- Epoch  2  Avg. Training Loss: 0.0335\n",
            " -- Epoch  3  Avg. Training Loss: 0.0314\n",
            " -- Epoch  4  Avg. Training Loss: 0.0300\n",
            " -- Epoch  5  Avg. Training Loss: 0.0291\n",
            " -- Epoch  6  Avg. Training Loss: 0.0283\n",
            " -- Epoch  7  Avg. Training Loss: 0.0277\n",
            " -- Epoch  8  Avg. Training Loss: 0.0272\n",
            " -- Epoch  9  Avg. Training Loss: 0.0268\n",
            " -- Epoch 10  Avg. Training Loss: 0.0264\n",
            "0:00:17.855353\n",
            " -- Epoch  1  Avg. Training Loss: 0.0390\n",
            " -- Epoch  2  Avg. Training Loss: 0.0346\n",
            " -- Epoch  3  Avg. Training Loss: 0.0324\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0298\n",
            " -- Epoch  6  Avg. Training Loss: 0.0289\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0267\n",
            "0:00:30.890492\n",
            " -- Epoch  1  Avg. Training Loss: 0.0426\n",
            " -- Epoch  2  Avg. Training Loss: 0.0377\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0336\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0314\n",
            " -- Epoch  7  Avg. Training Loss: 0.0306\n",
            " -- Epoch  8  Avg. Training Loss: 0.0300\n",
            " -- Epoch  9  Avg. Training Loss: 0.0294\n",
            " -- Epoch 10  Avg. Training Loss: 0.0289\n",
            "0:00:14.481319\n",
            " -- Epoch  1  Avg. Training Loss: 0.0401\n",
            " -- Epoch  2  Avg. Training Loss: 0.0351\n",
            " -- Epoch  3  Avg. Training Loss: 0.0327\n",
            " -- Epoch  4  Avg. Training Loss: 0.0312\n",
            " -- Epoch  5  Avg. Training Loss: 0.0301\n",
            " -- Epoch  6  Avg. Training Loss: 0.0293\n",
            " -- Epoch  7  Avg. Training Loss: 0.0286\n",
            " -- Epoch  8  Avg. Training Loss: 0.0281\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:14.116660\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.450698\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.379481\n",
            " -- Epoch  1  Avg. Training Loss: 0.0578\n",
            " -- Epoch  2  Avg. Training Loss: 0.0442\n",
            " -- Epoch  3  Avg. Training Loss: 0.0387\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0335\n",
            " -- Epoch  6  Avg. Training Loss: 0.0320\n",
            " -- Epoch  7  Avg. Training Loss: 0.0308\n",
            " -- Epoch  8  Avg. Training Loss: 0.0298\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0283\n",
            "0:00:33.005083\n",
            " -- Epoch  1  Avg. Training Loss: 0.0470\n",
            " -- Epoch  2  Avg. Training Loss: 0.0385\n",
            " -- Epoch  3  Avg. Training Loss: 0.0348\n",
            " -- Epoch  4  Avg. Training Loss: 0.0326\n",
            " -- Epoch  5  Avg. Training Loss: 0.0311\n",
            " -- Epoch  6  Avg. Training Loss: 0.0300\n",
            " -- Epoch  7  Avg. Training Loss: 0.0291\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:23.039987\n",
            " -- Epoch  1  Avg. Training Loss: 0.0401\n",
            " -- Epoch  2  Avg. Training Loss: 0.0351\n",
            " -- Epoch  3  Avg. Training Loss: 0.0327\n",
            " -- Epoch  4  Avg. Training Loss: 0.0312\n",
            " -- Epoch  5  Avg. Training Loss: 0.0301\n",
            " -- Epoch  6  Avg. Training Loss: 0.0293\n",
            " -- Epoch  7  Avg. Training Loss: 0.0286\n",
            " -- Epoch  8  Avg. Training Loss: 0.0281\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:14.333158\n",
            " -- Epoch  1  Avg. Training Loss: 0.0401\n",
            " -- Epoch  2  Avg. Training Loss: 0.0351\n",
            " -- Epoch  3  Avg. Training Loss: 0.0327\n",
            " -- Epoch  4  Avg. Training Loss: 0.0312\n",
            " -- Epoch  5  Avg. Training Loss: 0.0301\n",
            " -- Epoch  6  Avg. Training Loss: 0.0293\n",
            " -- Epoch  7  Avg. Training Loss: 0.0286\n",
            " -- Epoch  8  Avg. Training Loss: 0.0281\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:13.810075\n",
            " -- Epoch  1  Avg. Training Loss: 0.0460\n",
            " -- Epoch  2  Avg. Training Loss: 0.0402\n",
            " -- Epoch  3  Avg. Training Loss: 0.0374\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0343\n",
            " -- Epoch  6  Avg. Training Loss: 0.0332\n",
            " -- Epoch  7  Avg. Training Loss: 0.0324\n",
            " -- Epoch  8  Avg. Training Loss: 0.0317\n",
            " -- Epoch  9  Avg. Training Loss: 0.0311\n",
            " -- Epoch 10  Avg. Training Loss: 0.0306\n",
            "0:00:09.952833\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:32.176232\n",
            " -- Epoch  1  Avg. Training Loss: 0.0365\n",
            " -- Epoch  2  Avg. Training Loss: 0.0325\n",
            " -- Epoch  3  Avg. Training Loss: 0.0305\n",
            " -- Epoch  4  Avg. Training Loss: 0.0292\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0266\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0259\n",
            "0:00:29.836524\n",
            " -- Epoch  1  Avg. Training Loss: 0.0355\n",
            " -- Epoch  2  Avg. Training Loss: 0.0319\n",
            " -- Epoch  3  Avg. Training Loss: 0.0301\n",
            " -- Epoch  4  Avg. Training Loss: 0.0290\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0275\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0265\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0258\n",
            "0:00:39.918452\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:31.593962\n",
            " -- Epoch  1  Avg. Training Loss: 0.0441\n",
            " -- Epoch  2  Avg. Training Loss: 0.0387\n",
            " -- Epoch  3  Avg. Training Loss: 0.0360\n",
            " -- Epoch  4  Avg. Training Loss: 0.0343\n",
            " -- Epoch  5  Avg. Training Loss: 0.0330\n",
            " -- Epoch  6  Avg. Training Loss: 0.0320\n",
            " -- Epoch  7  Avg. Training Loss: 0.0312\n",
            " -- Epoch  8  Avg. Training Loss: 0.0306\n",
            " -- Epoch  9  Avg. Training Loss: 0.0300\n",
            " -- Epoch 10  Avg. Training Loss: 0.0295\n",
            "0:00:06.901735\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:31.540749\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:21.871794\n",
            " -- Epoch  1  Avg. Training Loss: 0.0491\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0400\n",
            " -- Epoch  4  Avg. Training Loss: 0.0380\n",
            " -- Epoch  5  Avg. Training Loss: 0.0366\n",
            " -- Epoch  6  Avg. Training Loss: 0.0355\n",
            " -- Epoch  7  Avg. Training Loss: 0.0346\n",
            " -- Epoch  8  Avg. Training Loss: 0.0339\n",
            " -- Epoch  9  Avg. Training Loss: 0.0332\n",
            " -- Epoch 10  Avg. Training Loss: 0.0327\n",
            "0:00:06.861060\n",
            " -- Epoch  1  Avg. Training Loss: 0.0355\n",
            " -- Epoch  2  Avg. Training Loss: 0.0319\n",
            " -- Epoch  3  Avg. Training Loss: 0.0301\n",
            " -- Epoch  4  Avg. Training Loss: 0.0290\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0275\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0265\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0258\n",
            "0:00:43.096481\n",
            " -- Epoch  1  Avg. Training Loss: 0.0379\n",
            " -- Epoch  2  Avg. Training Loss: 0.0335\n",
            " -- Epoch  3  Avg. Training Loss: 0.0314\n",
            " -- Epoch  4  Avg. Training Loss: 0.0300\n",
            " -- Epoch  5  Avg. Training Loss: 0.0291\n",
            " -- Epoch  6  Avg. Training Loss: 0.0283\n",
            " -- Epoch  7  Avg. Training Loss: 0.0277\n",
            " -- Epoch  8  Avg. Training Loss: 0.0272\n",
            " -- Epoch  9  Avg. Training Loss: 0.0268\n",
            " -- Epoch 10  Avg. Training Loss: 0.0264\n",
            "0:00:18.377720\n",
            " -- Epoch  1  Avg. Training Loss: 0.0360\n",
            " -- Epoch  2  Avg. Training Loss: 0.0322\n",
            " -- Epoch  3  Avg. Training Loss: 0.0304\n",
            " -- Epoch  4  Avg. Training Loss: 0.0292\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0277\n",
            " -- Epoch  7  Avg. Training Loss: 0.0272\n",
            " -- Epoch  8  Avg. Training Loss: 0.0267\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0260\n",
            "0:00:30.625507\n",
            " -- Epoch  1  Avg. Training Loss: 0.0407\n",
            " -- Epoch  2  Avg. Training Loss: 0.0361\n",
            " -- Epoch  3  Avg. Training Loss: 0.0338\n",
            " -- Epoch  4  Avg. Training Loss: 0.0322\n",
            " -- Epoch  5  Avg. Training Loss: 0.0311\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0295\n",
            " -- Epoch  8  Avg. Training Loss: 0.0289\n",
            " -- Epoch  9  Avg. Training Loss: 0.0284\n",
            " -- Epoch 10  Avg. Training Loss: 0.0279\n",
            "0:00:13.173425\n",
            " -- Epoch  1  Avg. Training Loss: 0.0374\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0313\n",
            " -- Epoch  4  Avg. Training Loss: 0.0299\n",
            " -- Epoch  5  Avg. Training Loss: 0.0289\n",
            " -- Epoch  6  Avg. Training Loss: 0.0282\n",
            " -- Epoch  7  Avg. Training Loss: 0.0275\n",
            " -- Epoch  8  Avg. Training Loss: 0.0270\n",
            " -- Epoch  9  Avg. Training Loss: 0.0266\n",
            " -- Epoch 10  Avg. Training Loss: 0.0262\n",
            "0:00:29.829382\n",
            " -- Epoch  1  Avg. Training Loss: 0.0362\n",
            " -- Epoch  2  Avg. Training Loss: 0.0323\n",
            " -- Epoch  3  Avg. Training Loss: 0.0303\n",
            " -- Epoch  4  Avg. Training Loss: 0.0291\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0266\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0259\n",
            "0:00:32.967177\n",
            " -- Epoch  1  Avg. Training Loss: 0.0365\n",
            " -- Epoch  2  Avg. Training Loss: 0.0325\n",
            " -- Epoch  3  Avg. Training Loss: 0.0305\n",
            " -- Epoch  4  Avg. Training Loss: 0.0292\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0276\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0266\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0259\n",
            "0:00:30.319443\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.318798\n",
            " -- Epoch  1  Avg. Training Loss: 0.0425\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0347\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0318\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0302\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0291\n",
            " -- Epoch 10  Avg. Training Loss: 0.0286\n",
            "0:00:09.527448\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:33.880339\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.735461\n",
            " -- Epoch  1  Avg. Training Loss: 0.0393\n",
            " -- Epoch  2  Avg. Training Loss: 0.0342\n",
            " -- Epoch  3  Avg. Training Loss: 0.0319\n",
            " -- Epoch  4  Avg. Training Loss: 0.0305\n",
            " -- Epoch  5  Avg. Training Loss: 0.0295\n",
            " -- Epoch  6  Avg. Training Loss: 0.0287\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0268\n",
            "0:00:13.558541\n",
            "[====                ] 20%0:53:07.693659\n",
            "Generation #1\n",
            " -- Epoch  1  Avg. Training Loss: 0.0384\n",
            " -- Epoch  2  Avg. Training Loss: 0.0337\n",
            " -- Epoch  3  Avg. Training Loss: 0.0314\n",
            " -- Epoch  4  Avg. Training Loss: 0.0300\n",
            " -- Epoch  5  Avg. Training Loss: 0.0290\n",
            " -- Epoch  6  Avg. Training Loss: 0.0282\n",
            " -- Epoch  7  Avg. Training Loss: 0.0276\n",
            " -- Epoch  8  Avg. Training Loss: 0.0270\n",
            " -- Epoch  9  Avg. Training Loss: 0.0266\n",
            " -- Epoch 10  Avg. Training Loss: 0.0262\n",
            "0:00:33.105909\n",
            " -- Epoch  1  Avg. Training Loss: 0.0571\n",
            " -- Epoch  2  Avg. Training Loss: 0.0443\n",
            " -- Epoch  3  Avg. Training Loss: 0.0391\n",
            " -- Epoch  4  Avg. Training Loss: 0.0361\n",
            " -- Epoch  5  Avg. Training Loss: 0.0341\n",
            " -- Epoch  6  Avg. Training Loss: 0.0326\n",
            " -- Epoch  7  Avg. Training Loss: 0.0314\n",
            " -- Epoch  8  Avg. Training Loss: 0.0305\n",
            " -- Epoch  9  Avg. Training Loss: 0.0297\n",
            " -- Epoch 10  Avg. Training Loss: 0.0291\n",
            "0:00:13.842966\n",
            " -- Epoch  1  Avg. Training Loss: 0.0346\n",
            " -- Epoch  2  Avg. Training Loss: 0.0311\n",
            " -- Epoch  3  Avg. Training Loss: 0.0294\n",
            " -- Epoch  4  Avg. Training Loss: 0.0282\n",
            " -- Epoch  5  Avg. Training Loss: 0.0274\n",
            " -- Epoch  6  Avg. Training Loss: 0.0268\n",
            " -- Epoch  7  Avg. Training Loss: 0.0263\n",
            " -- Epoch  8  Avg. Training Loss: 0.0259\n",
            " -- Epoch  9  Avg. Training Loss: 0.0255\n",
            " -- Epoch 10  Avg. Training Loss: 0.0252\n",
            "0:01:02.299605\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:42.525459\n",
            " -- Epoch  1  Avg. Training Loss: 0.0355\n",
            " -- Epoch  2  Avg. Training Loss: 0.0319\n",
            " -- Epoch  3  Avg. Training Loss: 0.0301\n",
            " -- Epoch  4  Avg. Training Loss: 0.0290\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0275\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0265\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0258\n",
            "0:00:42.115765\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.548410\n",
            " -- Epoch  1  Avg. Training Loss: 0.0401\n",
            " -- Epoch  2  Avg. Training Loss: 0.0351\n",
            " -- Epoch  3  Avg. Training Loss: 0.0327\n",
            " -- Epoch  4  Avg. Training Loss: 0.0312\n",
            " -- Epoch  5  Avg. Training Loss: 0.0301\n",
            " -- Epoch  6  Avg. Training Loss: 0.0293\n",
            " -- Epoch  7  Avg. Training Loss: 0.0286\n",
            " -- Epoch  8  Avg. Training Loss: 0.0281\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:14.060279\n",
            " -- Epoch  1  Avg. Training Loss: 0.0374\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0313\n",
            " -- Epoch  4  Avg. Training Loss: 0.0299\n",
            " -- Epoch  5  Avg. Training Loss: 0.0289\n",
            " -- Epoch  6  Avg. Training Loss: 0.0282\n",
            " -- Epoch  7  Avg. Training Loss: 0.0275\n",
            " -- Epoch  8  Avg. Training Loss: 0.0270\n",
            " -- Epoch  9  Avg. Training Loss: 0.0266\n",
            " -- Epoch 10  Avg. Training Loss: 0.0262\n",
            "0:00:29.973965\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:24.471795\n",
            " -- Epoch  1  Avg. Training Loss: 0.0375\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0298\n",
            " -- Epoch  5  Avg. Training Loss: 0.0288\n",
            " -- Epoch  6  Avg. Training Loss: 0.0280\n",
            " -- Epoch  7  Avg. Training Loss: 0.0274\n",
            " -- Epoch  8  Avg. Training Loss: 0.0268\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0260\n",
            "0:01:01.456285\n",
            " -- Epoch  1  Avg. Training Loss: 0.0398\n",
            " -- Epoch  2  Avg. Training Loss: 0.0349\n",
            " -- Epoch  3  Avg. Training Loss: 0.0325\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0298\n",
            " -- Epoch  6  Avg. Training Loss: 0.0289\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0267\n",
            "0:00:33.177075\n",
            " -- Epoch  1  Avg. Training Loss: 0.0385\n",
            " -- Epoch  2  Avg. Training Loss: 0.0343\n",
            " -- Epoch  3  Avg. Training Loss: 0.0321\n",
            " -- Epoch  4  Avg. Training Loss: 0.0307\n",
            " -- Epoch  5  Avg. Training Loss: 0.0296\n",
            " -- Epoch  6  Avg. Training Loss: 0.0287\n",
            " -- Epoch  7  Avg. Training Loss: 0.0280\n",
            " -- Epoch  8  Avg. Training Loss: 0.0274\n",
            " -- Epoch  9  Avg. Training Loss: 0.0269\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:00:32.175245\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.794413\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.982621\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.426563\n",
            " -- Epoch  1  Avg. Training Loss: 0.0355\n",
            " -- Epoch  2  Avg. Training Loss: 0.0319\n",
            " -- Epoch  3  Avg. Training Loss: 0.0301\n",
            " -- Epoch  4  Avg. Training Loss: 0.0290\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0275\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0265\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0258\n",
            "0:00:42.032984\n",
            " -- Epoch  1  Avg. Training Loss: 0.0373\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0299\n",
            " -- Epoch  5  Avg. Training Loss: 0.0289\n",
            " -- Epoch  6  Avg. Training Loss: 0.0281\n",
            " -- Epoch  7  Avg. Training Loss: 0.0275\n",
            " -- Epoch  8  Avg. Training Loss: 0.0269\n",
            " -- Epoch  9  Avg. Training Loss: 0.0265\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:34.069979\n",
            " -- Epoch  1  Avg. Training Loss: 0.0518\n",
            " -- Epoch  2  Avg. Training Loss: 0.0407\n",
            " -- Epoch  3  Avg. Training Loss: 0.0362\n",
            " -- Epoch  4  Avg. Training Loss: 0.0336\n",
            " -- Epoch  5  Avg. Training Loss: 0.0319\n",
            " -- Epoch  6  Avg. Training Loss: 0.0306\n",
            " -- Epoch  7  Avg. Training Loss: 0.0296\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0276\n",
            "0:00:22.625297\n",
            " -- Epoch  1  Avg. Training Loss: 0.0424\n",
            " -- Epoch  2  Avg. Training Loss: 0.0365\n",
            " -- Epoch  3  Avg. Training Loss: 0.0337\n",
            " -- Epoch  4  Avg. Training Loss: 0.0319\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0296\n",
            " -- Epoch  7  Avg. Training Loss: 0.0288\n",
            " -- Epoch  8  Avg. Training Loss: 0.0282\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:33.643455\n",
            " -- Epoch  1  Avg. Training Loss: 0.0379\n",
            " -- Epoch  2  Avg. Training Loss: 0.0335\n",
            " -- Epoch  3  Avg. Training Loss: 0.0314\n",
            " -- Epoch  4  Avg. Training Loss: 0.0300\n",
            " -- Epoch  5  Avg. Training Loss: 0.0291\n",
            " -- Epoch  6  Avg. Training Loss: 0.0283\n",
            " -- Epoch  7  Avg. Training Loss: 0.0277\n",
            " -- Epoch  8  Avg. Training Loss: 0.0272\n",
            " -- Epoch  9  Avg. Training Loss: 0.0268\n",
            " -- Epoch 10  Avg. Training Loss: 0.0264\n",
            "0:00:18.501641\n",
            " -- Epoch  1  Avg. Training Loss: 0.0426\n",
            " -- Epoch  2  Avg. Training Loss: 0.0367\n",
            " -- Epoch  3  Avg. Training Loss: 0.0338\n",
            " -- Epoch  4  Avg. Training Loss: 0.0320\n",
            " -- Epoch  5  Avg. Training Loss: 0.0307\n",
            " -- Epoch  6  Avg. Training Loss: 0.0297\n",
            " -- Epoch  7  Avg. Training Loss: 0.0290\n",
            " -- Epoch  8  Avg. Training Loss: 0.0283\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0273\n",
            "0:00:23.434771\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.937515\n",
            " -- Epoch  1  Avg. Training Loss: 0.0401\n",
            " -- Epoch  2  Avg. Training Loss: 0.0351\n",
            " -- Epoch  3  Avg. Training Loss: 0.0327\n",
            " -- Epoch  4  Avg. Training Loss: 0.0312\n",
            " -- Epoch  5  Avg. Training Loss: 0.0301\n",
            " -- Epoch  6  Avg. Training Loss: 0.0293\n",
            " -- Epoch  7  Avg. Training Loss: 0.0286\n",
            " -- Epoch  8  Avg. Training Loss: 0.0281\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:14.176701\n",
            " -- Epoch  1  Avg. Training Loss: 0.0398\n",
            " -- Epoch  2  Avg. Training Loss: 0.0349\n",
            " -- Epoch  3  Avg. Training Loss: 0.0325\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0298\n",
            " -- Epoch  6  Avg. Training Loss: 0.0289\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0267\n",
            "0:00:32.884982\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:33.832266\n",
            " -- Epoch  1  Avg. Training Loss: 0.0375\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0298\n",
            " -- Epoch  5  Avg. Training Loss: 0.0288\n",
            " -- Epoch  6  Avg. Training Loss: 0.0280\n",
            " -- Epoch  7  Avg. Training Loss: 0.0274\n",
            " -- Epoch  8  Avg. Training Loss: 0.0268\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0260\n",
            "0:01:01.159329\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.992238\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:31.223276\n",
            " -- Epoch  1  Avg. Training Loss: 0.0385\n",
            " -- Epoch  2  Avg. Training Loss: 0.0343\n",
            " -- Epoch  3  Avg. Training Loss: 0.0321\n",
            " -- Epoch  4  Avg. Training Loss: 0.0307\n",
            " -- Epoch  5  Avg. Training Loss: 0.0296\n",
            " -- Epoch  6  Avg. Training Loss: 0.0287\n",
            " -- Epoch  7  Avg. Training Loss: 0.0280\n",
            " -- Epoch  8  Avg. Training Loss: 0.0274\n",
            " -- Epoch  9  Avg. Training Loss: 0.0269\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:00:32.745312\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:31.924741\n",
            " -- Epoch  1  Avg. Training Loss: 0.0402\n",
            " -- Epoch  2  Avg. Training Loss: 0.0356\n",
            " -- Epoch  3  Avg. Training Loss: 0.0333\n",
            " -- Epoch  4  Avg. Training Loss: 0.0317\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0297\n",
            " -- Epoch  7  Avg. Training Loss: 0.0290\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0279\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:22.033028\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.107456\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:33.347699\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:33.475317\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:31.834833\n",
            " -- Epoch  1  Avg. Training Loss: 0.0362\n",
            " -- Epoch  2  Avg. Training Loss: 0.0324\n",
            " -- Epoch  3  Avg. Training Loss: 0.0305\n",
            " -- Epoch  4  Avg. Training Loss: 0.0292\n",
            " -- Epoch  5  Avg. Training Loss: 0.0283\n",
            " -- Epoch  6  Avg. Training Loss: 0.0277\n",
            " -- Epoch  7  Avg. Training Loss: 0.0271\n",
            " -- Epoch  8  Avg. Training Loss: 0.0266\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0259\n",
            "0:00:33.520020\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:41.098302\n",
            " -- Epoch  1  Avg. Training Loss: 0.0398\n",
            " -- Epoch  2  Avg. Training Loss: 0.0349\n",
            " -- Epoch  3  Avg. Training Loss: 0.0325\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0298\n",
            " -- Epoch  6  Avg. Training Loss: 0.0289\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0267\n",
            "0:00:32.729679\n",
            " -- Epoch  1  Avg. Training Loss: 0.0433\n",
            " -- Epoch  2  Avg. Training Loss: 0.0373\n",
            " -- Epoch  3  Avg. Training Loss: 0.0343\n",
            " -- Epoch  4  Avg. Training Loss: 0.0325\n",
            " -- Epoch  5  Avg. Training Loss: 0.0311\n",
            " -- Epoch  6  Avg. Training Loss: 0.0301\n",
            " -- Epoch  7  Avg. Training Loss: 0.0293\n",
            " -- Epoch  8  Avg. Training Loss: 0.0286\n",
            " -- Epoch  9  Avg. Training Loss: 0.0280\n",
            " -- Epoch 10  Avg. Training Loss: 0.0275\n",
            "0:00:21.251964\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.593078\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:30.836075\n",
            " -- Epoch  1  Avg. Training Loss: 0.0551\n",
            " -- Epoch  2  Avg. Training Loss: 0.0421\n",
            " -- Epoch  3  Avg. Training Loss: 0.0370\n",
            " -- Epoch  4  Avg. Training Loss: 0.0342\n",
            " -- Epoch  5  Avg. Training Loss: 0.0323\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0299\n",
            " -- Epoch  8  Avg. Training Loss: 0.0291\n",
            " -- Epoch  9  Avg. Training Loss: 0.0284\n",
            " -- Epoch 10  Avg. Training Loss: 0.0278\n",
            "0:00:30.167832\n",
            " -- Epoch  1  Avg. Training Loss: 0.0398\n",
            " -- Epoch  2  Avg. Training Loss: 0.0354\n",
            " -- Epoch  3  Avg. Training Loss: 0.0331\n",
            " -- Epoch  4  Avg. Training Loss: 0.0315\n",
            " -- Epoch  5  Avg. Training Loss: 0.0304\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0288\n",
            " -- Epoch  8  Avg. Training Loss: 0.0282\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:24.255065\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.873953\n",
            " -- Epoch  1  Avg. Training Loss: 0.0390\n",
            " -- Epoch  2  Avg. Training Loss: 0.0346\n",
            " -- Epoch  3  Avg. Training Loss: 0.0324\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0298\n",
            " -- Epoch  6  Avg. Training Loss: 0.0289\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0267\n",
            "0:00:30.273147\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.351249\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.532949\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.303536\n",
            " -- Epoch  1  Avg. Training Loss: 0.0578\n",
            " -- Epoch  2  Avg. Training Loss: 0.0442\n",
            " -- Epoch  3  Avg. Training Loss: 0.0387\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0335\n",
            " -- Epoch  6  Avg. Training Loss: 0.0320\n",
            " -- Epoch  7  Avg. Training Loss: 0.0308\n",
            " -- Epoch  8  Avg. Training Loss: 0.0298\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0283\n",
            "0:00:33.853020\n",
            "[======              ] 30%1:19:38.163128\n",
            "Generation #2\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.545645\n",
            " -- Epoch  1  Avg. Training Loss: 0.0503\n",
            " -- Epoch  2  Avg. Training Loss: 0.0409\n",
            " -- Epoch  3  Avg. Training Loss: 0.0368\n",
            " -- Epoch  4  Avg. Training Loss: 0.0343\n",
            " -- Epoch  5  Avg. Training Loss: 0.0326\n",
            " -- Epoch  6  Avg. Training Loss: 0.0313\n",
            " -- Epoch  7  Avg. Training Loss: 0.0303\n",
            " -- Epoch  8  Avg. Training Loss: 0.0294\n",
            " -- Epoch  9  Avg. Training Loss: 0.0287\n",
            " -- Epoch 10  Avg. Training Loss: 0.0281\n",
            "0:00:33.548016\n",
            " -- Epoch  1  Avg. Training Loss: 0.0480\n",
            " -- Epoch  2  Avg. Training Loss: 0.0391\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0285\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0273\n",
            "0:01:02.708129\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.238007\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.681337\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.493127\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.811472\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:01:02.297275\n",
            " -- Epoch  1  Avg. Training Loss: 0.0425\n",
            " -- Epoch  2  Avg. Training Loss: 0.0368\n",
            " -- Epoch  3  Avg. Training Loss: 0.0340\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0308\n",
            " -- Epoch  6  Avg. Training Loss: 0.0297\n",
            " -- Epoch  7  Avg. Training Loss: 0.0289\n",
            " -- Epoch  8  Avg. Training Loss: 0.0282\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0271\n",
            "0:00:23.870614\n",
            " -- Epoch  1  Avg. Training Loss: 0.0480\n",
            " -- Epoch  2  Avg. Training Loss: 0.0391\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0285\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0273\n",
            "0:00:59.889958\n",
            " -- Epoch  1  Avg. Training Loss: 0.0528\n",
            " -- Epoch  2  Avg. Training Loss: 0.0428\n",
            " -- Epoch  3  Avg. Training Loss: 0.0384\n",
            " -- Epoch  4  Avg. Training Loss: 0.0357\n",
            " -- Epoch  5  Avg. Training Loss: 0.0338\n",
            " -- Epoch  6  Avg. Training Loss: 0.0325\n",
            " -- Epoch  7  Avg. Training Loss: 0.0314\n",
            " -- Epoch  8  Avg. Training Loss: 0.0305\n",
            " -- Epoch  9  Avg. Training Loss: 0.0297\n",
            " -- Epoch 10  Avg. Training Loss: 0.0291\n",
            "0:00:21.470681\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:33.174589\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:42.589421\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.492079\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:31.744219\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.351571\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.669009\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.000083\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.402731\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.380456\n",
            " -- Epoch  1  Avg. Training Loss: 0.0386\n",
            " -- Epoch  2  Avg. Training Loss: 0.0344\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0299\n",
            " -- Epoch  6  Avg. Training Loss: 0.0291\n",
            " -- Epoch  7  Avg. Training Loss: 0.0285\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0275\n",
            " -- Epoch 10  Avg. Training Loss: 0.0271\n",
            "0:00:30.561119\n",
            " -- Epoch  1  Avg. Training Loss: 0.0440\n",
            " -- Epoch  2  Avg. Training Loss: 0.0372\n",
            " -- Epoch  3  Avg. Training Loss: 0.0339\n",
            " -- Epoch  4  Avg. Training Loss: 0.0319\n",
            " -- Epoch  5  Avg. Training Loss: 0.0304\n",
            " -- Epoch  6  Avg. Training Loss: 0.0293\n",
            " -- Epoch  7  Avg. Training Loss: 0.0285\n",
            " -- Epoch  8  Avg. Training Loss: 0.0277\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:01:02.137857\n",
            " -- Epoch  1  Avg. Training Loss: 0.0400\n",
            " -- Epoch  2  Avg. Training Loss: 0.0351\n",
            " -- Epoch  3  Avg. Training Loss: 0.0327\n",
            " -- Epoch  4  Avg. Training Loss: 0.0311\n",
            " -- Epoch  5  Avg. Training Loss: 0.0300\n",
            " -- Epoch  6  Avg. Training Loss: 0.0291\n",
            " -- Epoch  7  Avg. Training Loss: 0.0284\n",
            " -- Epoch  8  Avg. Training Loss: 0.0278\n",
            " -- Epoch  9  Avg. Training Loss: 0.0273\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:23.710662\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0362\n",
            " -- Epoch  3  Avg. Training Loss: 0.0332\n",
            " -- Epoch  4  Avg. Training Loss: 0.0314\n",
            " -- Epoch  5  Avg. Training Loss: 0.0300\n",
            " -- Epoch  6  Avg. Training Loss: 0.0290\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:01:01.780915\n",
            " -- Epoch  1  Avg. Training Loss: 0.0578\n",
            " -- Epoch  2  Avg. Training Loss: 0.0442\n",
            " -- Epoch  3  Avg. Training Loss: 0.0387\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0335\n",
            " -- Epoch  6  Avg. Training Loss: 0.0320\n",
            " -- Epoch  7  Avg. Training Loss: 0.0308\n",
            " -- Epoch  8  Avg. Training Loss: 0.0298\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0283\n",
            "0:00:33.138506\n",
            " -- Epoch  1  Avg. Training Loss: 0.0380\n",
            " -- Epoch  2  Avg. Training Loss: 0.0338\n",
            " -- Epoch  3  Avg. Training Loss: 0.0316\n",
            " -- Epoch  4  Avg. Training Loss: 0.0302\n",
            " -- Epoch  5  Avg. Training Loss: 0.0292\n",
            " -- Epoch  6  Avg. Training Loss: 0.0284\n",
            " -- Epoch  7  Avg. Training Loss: 0.0278\n",
            " -- Epoch  8  Avg. Training Loss: 0.0272\n",
            " -- Epoch  9  Avg. Training Loss: 0.0268\n",
            " -- Epoch 10  Avg. Training Loss: 0.0264\n",
            "0:00:23.864533\n",
            " -- Epoch  1  Avg. Training Loss: 0.0375\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0298\n",
            " -- Epoch  5  Avg. Training Loss: 0.0288\n",
            " -- Epoch  6  Avg. Training Loss: 0.0280\n",
            " -- Epoch  7  Avg. Training Loss: 0.0274\n",
            " -- Epoch  8  Avg. Training Loss: 0.0268\n",
            " -- Epoch  9  Avg. Training Loss: 0.0264\n",
            " -- Epoch 10  Avg. Training Loss: 0.0260\n",
            "0:01:01.018950\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.329955\n",
            " -- Epoch  1  Avg. Training Loss: 0.0470\n",
            " -- Epoch  2  Avg. Training Loss: 0.0385\n",
            " -- Epoch  3  Avg. Training Loss: 0.0348\n",
            " -- Epoch  4  Avg. Training Loss: 0.0326\n",
            " -- Epoch  5  Avg. Training Loss: 0.0311\n",
            " -- Epoch  6  Avg. Training Loss: 0.0300\n",
            " -- Epoch  7  Avg. Training Loss: 0.0291\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:24.035303\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.252122\n",
            " -- Epoch  1  Avg. Training Loss: 0.0388\n",
            " -- Epoch  2  Avg. Training Loss: 0.0345\n",
            " -- Epoch  3  Avg. Training Loss: 0.0323\n",
            " -- Epoch  4  Avg. Training Loss: 0.0308\n",
            " -- Epoch  5  Avg. Training Loss: 0.0297\n",
            " -- Epoch  6  Avg. Training Loss: 0.0288\n",
            " -- Epoch  7  Avg. Training Loss: 0.0281\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0266\n",
            "0:00:31.612095\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.098100\n",
            " -- Epoch  1  Avg. Training Loss: 0.0685\n",
            " -- Epoch  2  Avg. Training Loss: 0.0489\n",
            " -- Epoch  3  Avg. Training Loss: 0.0415\n",
            " -- Epoch  4  Avg. Training Loss: 0.0375\n",
            " -- Epoch  5  Avg. Training Loss: 0.0349\n",
            " -- Epoch  6  Avg. Training Loss: 0.0330\n",
            " -- Epoch  7  Avg. Training Loss: 0.0316\n",
            " -- Epoch  8  Avg. Training Loss: 0.0305\n",
            " -- Epoch  9  Avg. Training Loss: 0.0296\n",
            " -- Epoch 10  Avg. Training Loss: 0.0288\n",
            "0:00:31.361299\n",
            " -- Epoch  1  Avg. Training Loss: 0.0470\n",
            " -- Epoch  2  Avg. Training Loss: 0.0385\n",
            " -- Epoch  3  Avg. Training Loss: 0.0348\n",
            " -- Epoch  4  Avg. Training Loss: 0.0326\n",
            " -- Epoch  5  Avg. Training Loss: 0.0311\n",
            " -- Epoch  6  Avg. Training Loss: 0.0300\n",
            " -- Epoch  7  Avg. Training Loss: 0.0291\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:24.095307\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:42.807460\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:33.730751\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:58.386926\n",
            " -- Epoch  1  Avg. Training Loss: 0.0373\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0299\n",
            " -- Epoch  5  Avg. Training Loss: 0.0289\n",
            " -- Epoch  6  Avg. Training Loss: 0.0281\n",
            " -- Epoch  7  Avg. Training Loss: 0.0275\n",
            " -- Epoch  8  Avg. Training Loss: 0.0269\n",
            " -- Epoch  9  Avg. Training Loss: 0.0265\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:33.039369\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.587025\n",
            " -- Epoch  1  Avg. Training Loss: 0.0578\n",
            " -- Epoch  2  Avg. Training Loss: 0.0442\n",
            " -- Epoch  3  Avg. Training Loss: 0.0387\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0335\n",
            " -- Epoch  6  Avg. Training Loss: 0.0320\n",
            " -- Epoch  7  Avg. Training Loss: 0.0308\n",
            " -- Epoch  8  Avg. Training Loss: 0.0298\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0283\n",
            "0:00:32.473617\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:25.136557\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.648892\n",
            " -- Epoch  1  Avg. Training Loss: 0.0355\n",
            " -- Epoch  2  Avg. Training Loss: 0.0319\n",
            " -- Epoch  3  Avg. Training Loss: 0.0301\n",
            " -- Epoch  4  Avg. Training Loss: 0.0290\n",
            " -- Epoch  5  Avg. Training Loss: 0.0282\n",
            " -- Epoch  6  Avg. Training Loss: 0.0275\n",
            " -- Epoch  7  Avg. Training Loss: 0.0270\n",
            " -- Epoch  8  Avg. Training Loss: 0.0265\n",
            " -- Epoch  9  Avg. Training Loss: 0.0262\n",
            " -- Epoch 10  Avg. Training Loss: 0.0258\n",
            "0:00:41.264299\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.656714\n",
            " -- Epoch  1  Avg. Training Loss: 0.0373\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0299\n",
            " -- Epoch  5  Avg. Training Loss: 0.0289\n",
            " -- Epoch  6  Avg. Training Loss: 0.0281\n",
            " -- Epoch  7  Avg. Training Loss: 0.0275\n",
            " -- Epoch  8  Avg. Training Loss: 0.0269\n",
            " -- Epoch  9  Avg. Training Loss: 0.0265\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:32.416183\n",
            "[========            ] 40%1:46:58.964683\n",
            "Generation #3\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:42.317562\n",
            " -- Epoch  1  Avg. Training Loss: 0.0578\n",
            " -- Epoch  2  Avg. Training Loss: 0.0442\n",
            " -- Epoch  3  Avg. Training Loss: 0.0387\n",
            " -- Epoch  4  Avg. Training Loss: 0.0356\n",
            " -- Epoch  5  Avg. Training Loss: 0.0335\n",
            " -- Epoch  6  Avg. Training Loss: 0.0320\n",
            " -- Epoch  7  Avg. Training Loss: 0.0308\n",
            " -- Epoch  8  Avg. Training Loss: 0.0298\n",
            " -- Epoch  9  Avg. Training Loss: 0.0290\n",
            " -- Epoch 10  Avg. Training Loss: 0.0283\n",
            "0:00:32.373587\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:58.638302\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:40.394254\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:43.030505\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.620409\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.478177\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:23.780086\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0362\n",
            " -- Epoch  3  Avg. Training Loss: 0.0332\n",
            " -- Epoch  4  Avg. Training Loss: 0.0314\n",
            " -- Epoch  5  Avg. Training Loss: 0.0300\n",
            " -- Epoch  6  Avg. Training Loss: 0.0290\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:01:03.376682\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.947851\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.911967\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.835732\n",
            " -- Epoch  1  Avg. Training Loss: 0.0425\n",
            " -- Epoch  2  Avg. Training Loss: 0.0368\n",
            " -- Epoch  3  Avg. Training Loss: 0.0340\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0308\n",
            " -- Epoch  6  Avg. Training Loss: 0.0297\n",
            " -- Epoch  7  Avg. Training Loss: 0.0289\n",
            " -- Epoch  8  Avg. Training Loss: 0.0282\n",
            " -- Epoch  9  Avg. Training Loss: 0.0276\n",
            " -- Epoch 10  Avg. Training Loss: 0.0271\n",
            "0:00:23.906864\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.516160\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.102836\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.642085\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.622473\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.188536\n",
            " -- Epoch  1  Avg. Training Loss: 0.0373\n",
            " -- Epoch  2  Avg. Training Loss: 0.0332\n",
            " -- Epoch  3  Avg. Training Loss: 0.0311\n",
            " -- Epoch  4  Avg. Training Loss: 0.0298\n",
            " -- Epoch  5  Avg. Training Loss: 0.0288\n",
            " -- Epoch  6  Avg. Training Loss: 0.0281\n",
            " -- Epoch  7  Avg. Training Loss: 0.0274\n",
            " -- Epoch  8  Avg. Training Loss: 0.0269\n",
            " -- Epoch  9  Avg. Training Loss: 0.0265\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:42.065589\n",
            " -- Epoch  1  Avg. Training Loss: 0.0480\n",
            " -- Epoch  2  Avg. Training Loss: 0.0391\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0285\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0273\n",
            "0:01:01.195555\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.682116\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.359848\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:40.881902\n",
            " -- Epoch  1  Avg. Training Loss: 0.0461\n",
            " -- Epoch  2  Avg. Training Loss: 0.0378\n",
            " -- Epoch  3  Avg. Training Loss: 0.0342\n",
            " -- Epoch  4  Avg. Training Loss: 0.0321\n",
            " -- Epoch  5  Avg. Training Loss: 0.0306\n",
            " -- Epoch  6  Avg. Training Loss: 0.0295\n",
            " -- Epoch  7  Avg. Training Loss: 0.0287\n",
            " -- Epoch  8  Avg. Training Loss: 0.0280\n",
            " -- Epoch  9  Avg. Training Loss: 0.0274\n",
            " -- Epoch 10  Avg. Training Loss: 0.0269\n",
            "0:00:33.210910\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.236383\n",
            " -- Epoch  1  Avg. Training Loss: 0.0373\n",
            " -- Epoch  2  Avg. Training Loss: 0.0333\n",
            " -- Epoch  3  Avg. Training Loss: 0.0312\n",
            " -- Epoch  4  Avg. Training Loss: 0.0299\n",
            " -- Epoch  5  Avg. Training Loss: 0.0289\n",
            " -- Epoch  6  Avg. Training Loss: 0.0281\n",
            " -- Epoch  7  Avg. Training Loss: 0.0275\n",
            " -- Epoch  8  Avg. Training Loss: 0.0269\n",
            " -- Epoch  9  Avg. Training Loss: 0.0265\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:32.837658\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.388769\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:23.148586\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0362\n",
            " -- Epoch  3  Avg. Training Loss: 0.0332\n",
            " -- Epoch  4  Avg. Training Loss: 0.0314\n",
            " -- Epoch  5  Avg. Training Loss: 0.0300\n",
            " -- Epoch  6  Avg. Training Loss: 0.0290\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:01:03.379998\n",
            " -- Epoch  1  Avg. Training Loss: 0.0512\n",
            " -- Epoch  2  Avg. Training Loss: 0.0419\n",
            " -- Epoch  3  Avg. Training Loss: 0.0378\n",
            " -- Epoch  4  Avg. Training Loss: 0.0353\n",
            " -- Epoch  5  Avg. Training Loss: 0.0335\n",
            " -- Epoch  6  Avg. Training Loss: 0.0322\n",
            " -- Epoch  7  Avg. Training Loss: 0.0311\n",
            " -- Epoch  8  Avg. Training Loss: 0.0303\n",
            " -- Epoch  9  Avg. Training Loss: 0.0295\n",
            " -- Epoch 10  Avg. Training Loss: 0.0289\n",
            "0:00:24.515435\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.642128\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.480419\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.051017\n",
            " -- Epoch  1  Avg. Training Loss: 0.0398\n",
            " -- Epoch  2  Avg. Training Loss: 0.0349\n",
            " -- Epoch  3  Avg. Training Loss: 0.0325\n",
            " -- Epoch  4  Avg. Training Loss: 0.0309\n",
            " -- Epoch  5  Avg. Training Loss: 0.0298\n",
            " -- Epoch  6  Avg. Training Loss: 0.0289\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0271\n",
            " -- Epoch 10  Avg. Training Loss: 0.0267\n",
            "0:00:33.817398\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.898218\n",
            "[==========          ] 50%2:13:39.001135\n",
            "Generation #4\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.367914\n",
            " -- Epoch  1  Avg. Training Loss: 0.0553\n",
            " -- Epoch  2  Avg. Training Loss: 0.0430\n",
            " -- Epoch  3  Avg. Training Loss: 0.0380\n",
            " -- Epoch  4  Avg. Training Loss: 0.0351\n",
            " -- Epoch  5  Avg. Training Loss: 0.0331\n",
            " -- Epoch  6  Avg. Training Loss: 0.0317\n",
            " -- Epoch  7  Avg. Training Loss: 0.0305\n",
            " -- Epoch  8  Avg. Training Loss: 0.0296\n",
            " -- Epoch  9  Avg. Training Loss: 0.0289\n",
            " -- Epoch 10  Avg. Training Loss: 0.0282\n",
            "0:00:24.343623\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.848104\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.227179\n",
            " -- Epoch  1  Avg. Training Loss: 0.0373\n",
            " -- Epoch  2  Avg. Training Loss: 0.0332\n",
            " -- Epoch  3  Avg. Training Loss: 0.0311\n",
            " -- Epoch  4  Avg. Training Loss: 0.0298\n",
            " -- Epoch  5  Avg. Training Loss: 0.0288\n",
            " -- Epoch  6  Avg. Training Loss: 0.0281\n",
            " -- Epoch  7  Avg. Training Loss: 0.0274\n",
            " -- Epoch  8  Avg. Training Loss: 0.0269\n",
            " -- Epoch  9  Avg. Training Loss: 0.0265\n",
            " -- Epoch 10  Avg. Training Loss: 0.0261\n",
            "0:00:40.361881\n",
            " -- Epoch  1  Avg. Training Loss: nan\n",
            " -- Epoch  2  Avg. Training Loss: nan\n",
            " -- Epoch  3  Avg. Training Loss: nan\n",
            " -- Epoch  4  Avg. Training Loss: nan\n",
            " -- Epoch  5  Avg. Training Loss: nan\n",
            " -- Epoch  6  Avg. Training Loss: nan\n",
            " -- Epoch  7  Avg. Training Loss: nan\n",
            " -- Epoch  8  Avg. Training Loss: nan\n",
            " -- Epoch  9  Avg. Training Loss: nan\n",
            " -- Epoch 10  Avg. Training Loss: nan\n",
            "0:00:59.836892\n",
            " -- Epoch  1  Avg. Training Loss: 0.0586\n",
            " -- Epoch  2  Avg. Training Loss: 0.0435\n",
            " -- Epoch  3  Avg. Training Loss: 0.0377\n",
            " -- Epoch  4  Avg. Training Loss: 0.0345\n",
            " -- Epoch  5  Avg. Training Loss: 0.0324\n",
            " -- Epoch  6  Avg. Training Loss: 0.0309\n",
            " -- Epoch  7  Avg. Training Loss: 0.0297\n",
            " -- Epoch  8  Avg. Training Loss: 0.0288\n",
            " -- Epoch  9  Avg. Training Loss: 0.0281\n",
            " -- Epoch 10  Avg. Training Loss: 0.0274\n",
            "0:00:40.989109\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.290637\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.838400\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.658113\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.789694\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.491784\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.583077\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.378425\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.664010\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.676736\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0362\n",
            " -- Epoch  3  Avg. Training Loss: 0.0332\n",
            " -- Epoch  4  Avg. Training Loss: 0.0314\n",
            " -- Epoch  5  Avg. Training Loss: 0.0300\n",
            " -- Epoch  6  Avg. Training Loss: 0.0290\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:01:01.531410\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.630119\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.676775\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.405038\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.125118\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.610588\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.539180\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.320334\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.722096\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.657688\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.595419\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.374034\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.684128\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.586072\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.074176\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.546204\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.322172\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0362\n",
            " -- Epoch  3  Avg. Training Loss: 0.0332\n",
            " -- Epoch  4  Avg. Training Loss: 0.0314\n",
            " -- Epoch  5  Avg. Training Loss: 0.0300\n",
            " -- Epoch  6  Avg. Training Loss: 0.0290\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:01:00.014841\n",
            " -- Epoch  1  Avg. Training Loss: 0.0423\n",
            " -- Epoch  2  Avg. Training Loss: 0.0362\n",
            " -- Epoch  3  Avg. Training Loss: 0.0332\n",
            " -- Epoch  4  Avg. Training Loss: 0.0314\n",
            " -- Epoch  5  Avg. Training Loss: 0.0300\n",
            " -- Epoch  6  Avg. Training Loss: 0.0290\n",
            " -- Epoch  7  Avg. Training Loss: 0.0282\n",
            " -- Epoch  8  Avg. Training Loss: 0.0276\n",
            " -- Epoch  9  Avg. Training Loss: 0.0270\n",
            " -- Epoch 10  Avg. Training Loss: 0.0265\n",
            "0:01:03.190732\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.217454\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.231483\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.594064\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:58.999499\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.578033\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.153719\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.459289\n",
            "[============        ] 60%2:54:58.009412\n",
            "Generation #5\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.025212\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.205176\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.422261\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:03.221159\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.330698\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.447226\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.871053\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:03.042119\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.397378\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.385860\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.244132\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.217794\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.830988\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.285458\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.399233\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.328254\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.676968\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.061606\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.960880\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.360826\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.990887\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.601737\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.871738\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:00:59.480356\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.715561\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.691225\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.211163\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.218266\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.010396\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.282070\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.106930\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.221955\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:03.513973\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:00.988742\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.758381\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:02.299842\n",
            " -- Epoch  1  Avg. Training Loss: 0.0477\n",
            " -- Epoch  2  Avg. Training Loss: 0.0392\n",
            " -- Epoch  3  Avg. Training Loss: 0.0353\n",
            " -- Epoch  4  Avg. Training Loss: 0.0330\n",
            " -- Epoch  5  Avg. Training Loss: 0.0314\n",
            " -- Epoch  6  Avg. Training Loss: 0.0302\n",
            " -- Epoch  7  Avg. Training Loss: 0.0292\n",
            " -- Epoch  8  Avg. Training Loss: 0.0284\n",
            " -- Epoch  9  Avg. Training Loss: 0.0278\n",
            " -- Epoch 10  Avg. Training Loss: 0.0272\n",
            "0:01:01.374280\n",
            "[==============      ] 70%Last Gen 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEJCAYAAACOr7BbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9dn38c+VjUDYV5WwCogbIkZw37HUWpcWLUu9a+tdu6h3tatdbuvtc/u0tbV20ccWW6u1LOLWYkXBBZdWDAQEBARkkSSAEHYSyH49f5xBj/FADkkmk+R8369XXpn9XCfKfGfmN/Mbc3dERETqSou6ABERaZkUECIikpACQkREElJAiIhIQgoIERFJSAEhIiIJhRoQZjbOzFab2Vozuz3B/P5mNs/M3jazZWZ2Wdy8EWY238xWmNk7ZpYdZq0iIvJxFtZzEGaWDqwBxgLFwEJgoruvjFtmCvC2uz9oZicAs919oJllAIuB69x9qZn1AHa7e00oxYqIyCdkhLjt0cBad18PYGYzgCuBlXHLONA5GO4CbA6GLwWWuftSAHffUd+H9ezZ0wcOHNg0lYuIpIhFixZtd/deieaFGRB9gaK48WJgTJ1l7gTmmtktQA5wSTB9GOBmNgfoBcxw93vqfoCZ3QjcCNC/f38KCgqa9AuIiLR1ZrbxUPOibqSeCDzi7rnAZcBjZpZGLLjOASYHv682s4vrruzuU9w9z93zevVKGIAiItJAYQbEJqBf3HhuMC3eDcBMAHefD2QDPYmdbbzu7tvdfT8wGxgVYq0iIlJHmAGxEBhqZoPMLAuYAMyqs0whcDGAmR1PLCBKgDnAyWbWIWiwPp+Pt12IiEjIQmuDcPdqM7uZ2M4+HXjY3VeY2V1AgbvPAr4DPGRmtxFrsL7eY7dV7TKzXxMLGSd2d9NzYdUqIiKfFNptrs0tLy/P1UgtInJkzGyRu+clmhd1I7WIiLRQCggREUkozOcgRESkkapqatlXXs2+8qrgd2y4tOKj4e457Zg0pn+Tf7YCQkQkBO7O/soa9pVXU1pRxd5g514av7Ov+Gi4tLyafRUfDe8Nlquorq33s07t31UBISLSHKqDo/bSimr2JtiBH+pIvu702nruATKDjlkZdMrOoGN2Bp2yM+mek0X/7h3olJ1J5+wMOraLze+UnRksk0Hn7MwPp3fMzqBdRnoofwcFhIi0Oe7Ogaoadu2vYvf+Svbsr4oNH6hk98FpB+J26HWO5A9U1d8vaFZ6WtyOPYNO7TLp173DJ3bgH9+xZ9CxXWYwPYOcrAzS0qwZ/iINo4AQkRbr4I4+tlOP7dh3H4gN7wp28rv3V7JrfxV7ggA4OFxZc+hLM+0z0+nS/qMddZf2meR2ax93xB6bd3C4c9wR/sHp2ZnhHLW3JAoIEQmdu1NeVcuu/cER/IdH8h8/qv/EtANVVB7mGnx2Zhpd22fRtUMmXTtkMrhnR7rlZNIlmNatQ/xw7HeX9pkpsXNvCgoIETkiByprPtyB7wou3+w+EDccTN99oCq4tFNZ746+XUbax3bgg3t2jA0f3LG3zwxCIAiDYKevHX24FBAiUi93Z2ZBET97fhW791cdcrmsjDS6BTv1Lu0zGdizA6d26EqXYKfeLTjS79I+i2452tG3dAoIETms7aUV3P7UO7z07lbGDOrOBcf1Do7i447og1DQjr5tUUCIyCG9tHIrtz+9jL3l1fzkM8fzlbMHtei7bqRpKSBE5BPKKqr53+dWMn1BEccf3Zmp/zmS447qFHVZ0swUECLyMYs27uK2x5dQtGs/Xz//WG4bOzS0B7GkZVNAiAgQ6/Pndy+/xwPz1nJ0l/Y8fuOZjB7UPeqyJEIKCBFh7bZ93Pb4Ut7ZtIfxp+Xy08+eQKfszKjLkogpIERSWG2t89f57/Oz51fRISudP3xxFONOOjrqsqSFUECIpKgP9pTzvSeX8sZ727nwuF78YvwIenfKjrosaUEUECIp6J/LNvPjZ5ZTWV3L/151EpPH9MdMt6/KxykgRFLIngNV/PQfy/n7ks2c0q8r9117CoN7dYy6LGmhFBAiKeLNddv57sylbN1XwW2XDOOmC48lI11vHZZDU0CItHHlVTX8as5q/vSvDQzqmcNT3ziLkf26Rl2WtAIKCJE2bOXmvdz6+Nus2VrKdWcM4IeXDadDlv7ZS3L0f4pIG1RT6zz0xnrunbuarh2y+MuXT+fC43pHXZa0MqFegDSzcWa22szWmtntCeb3N7N5Zva2mS0zs8sSzC81s++GWadIW1K0cz8Tp7zFz59fxSXH92HOrecpHKRBQjuDMLN04AFgLFAMLDSzWe6+Mm6xnwAz3f1BMzsBmA0MjJv/a+D5sGoUaUvcnScXFfM/z8b+id17zSl8blRf3b4qDRbmJabRwFp3Xw9gZjOAK4H4gHCgczDcBdh8cIaZXQVsAMpCrFGkTdhZVsmPnn6HF1Z8wOhB3bn3mlPo171D1GVJKxdmQPQFiuLGi4ExdZa5E5hrZrcAOcAlAGbWEfgBsbOPQ15eMrMbgRsB+vfv31R1i7Qq81Zt43tPLmPvgSp+dNlwbjhnMOl6Z4M0gahvgp4IPOLuucBlwGNmlkYsOO5z99LDrezuU9w9z93zevXqFX61Ii3I/spqfvzMO3z5kYX0yMniHzefzY3nHatwkCYT5hnEJqBf3HhuMC3eDcA4AHefb2bZQE9iZxrjzeweoCtQa2bl7n5/iPWKtBpvF+7i2zOX8v6OMm48bzDfHjtMr/uUJhdmQCwEhprZIGLBMAGYVGeZQuBi4BEzOx7IBkrc/dyDC5jZnUCpwkEk9s6G+19Zy/3z1nJU52ym/ecZnHlsj6jLkjYqtIBw92ozuxmYA6QDD7v7CjO7Cyhw91nAd4CHzOw2Yg3W17u7h1WTSGu2vqSU2x5fwtLiPXzu1L7ceeWJdNY7GyRE1lb2x3l5eV5QUBB1GSJNzt35W34hdz+3kuzMdO6+6mQ+M0LvbJCmYWaL3D0v0Tw9SS3Sgm3bW873n1rGq6tLOHdoT351zSn06ax3NkjzUECItFAvLN/CD59+hwNVNdx15Ylcd8YAPfQmzUoBIdLC7C2v4n9mreSpxcWMyO3Cr68dyZDeemeDND8FhEgLkr9+B9+euZQtew7wXxcN4ZaLh5KpdzZIRBQQIi1ARXUNv35xDVNeX8+A7h148htnMap/t6jLkhSngBCJ2KoP9nLrjCWs+mAfE0f35yefOZ6cdvqnKdHT/4UiEamtdR7+9wbueWE1ndtn8Ocv5XHx8X2iLkvkQwoIkQhs2n2A785cyvz1O7j0hD787HMn06Nju6jLEvkYBYRIM3J3/r5kE3f8fQW17twzfgTXnJar21elRVJAiDST3fsr+fEzy3nunS3kDejGfV8YqXc2SIumgBBpBq+vKeF7Ty5lZ1kl3x93HF9Tt9zSCiggRJrAgcoadpRVsKO0kp1llWwvrWBnWWz4/R1lzFmxlaG9O/LnL53OSX27RF2uSFIUECIJlFfVsKOskp2llWwvq2BnaWUsAMoqPwyB2HAsCPZX1iTcTruMNHrkZPHVcwfxnUuP0zsbpFVRQEhKqKiuie3USz++Y99eWsnO4Mh/R3DEv6O0grJD7PCz0tPo0TGL7jlZ9OjYjsE9c+iRk0X3jln0zGkXTM+iR047unfMIicrXQ3Q0mopIKRVqqyuDY7iP3lZ58MQKAsu85RWsq+iOuF2MtMttjMPduwDe3Sge067YCcfC4HuOVn0DEKhY7sM7fAlZSggpEVa9cFe3ly748Od/PbSj47ud5RVsq888Q4/I80+PLrvkZNF/+4dYuOf2NnHQqCTdvgih6SAkBZl7bZ93PfSezy3bAsA6Qd3+MER/sm5XWPDwWWdHvFH+znt6NxeO3yRpqKAkBahcMd+fvPyGv7+9ibaZ6Zzy0VDuO6MAfTs2I403Q4qEgkFhERq8+4D/P6VtTxRUER6mvGf5w7ma+cNVrcTIi2AAkIisW1fOf9v3jqm5RfiOJPH9OemC4fQW6/TFGkxFBDSrHaVVfKH19fx6JvvU1XjXHNaLjdfNITcbupyQqSlUUBIs9hbXsWf3tjAw//aQFllNVeN7Mu3Lh7KwJ45UZcmIoeggJBQlVVU88ib7zPl9fXsOVDFZScfxa2XDGNYn05RlyYi9VBASCjKq2r421sbefDVdewoq+Ti4b25beww9UMk0oooIKRJVVbX8nhBEfe/8h5b91ZwzpCefPvSYXq/skgrFGpAmNk44LdAOvAnd/95nfn9gUeBrsEyt7v7bDMbC/wcyAIqge+5+yth1iqNU11Ty9Nvb+J3L79H8a4D5A3oxm++cCpnHtsj6tJEpIFCCwgzSwceAMYCxcBCM5vl7ivjFvsJMNPdHzSzE4DZwEBgO/BZd99sZicBc4C+YdUqDVdb6zy7bDO/eek9NmwvY0RuF+6++mTOG9pTTzSLtHJhnkGMBta6+3oAM5sBXAnEB4QDnYPhLsBmAHd/O26ZFUB7M2vn7hUh1itHwN2Zs2Ir9724htVb9zH8qE5Mue40xp7QR8Eg0kaEGRB9gaK48WJgTJ1l7gTmmtktQA5wSYLtfB5YnCgczOxG4EaA/v37N0HJUh9359U1Jfx67hre2bSHwT1z+P3EU/nMyUerSwyRNibqRuqJwCPufq+ZnQk8ZmYnuXstgJmdCPwCuDTRyu4+BZgCkJeX581Uc8p6c9127p27hkUbd5HbrT2/uuYUrhp5DBnpaVGXJiIhCDMgNgH94sZzg2nxbgDGAbj7fDPLBnoC28wsF3gG+A93XxdinVKPRRt3ce/c1by5bgdHdc7m7qtP4prT+pGVoWAQacvqDQgzywEOuHutmQ0DhgPPu3tVPasuBIaa2SBiwTABmFRnmULgYuARMzseyAZKzKwr8Byxu5r+fUTfSJrM8k17uHfuauatLqFnxyz++/ITmDymv16bKZIikjmDeB0418y6AXOJ7fi/AEw+3EruXm1mNxO7AykdeNjdV5jZXUCBu88CvgM8ZGa3EWuwvt7dPVhvCHCHmd0RbPJSd9/WgO8oR2jN1n3c9+Ianl/+AV3aZ/L9ccfxpTMHktMu6iuSItKczP3wl+7NbLG7jwoaktu7+z1mtsTdRzZPicnJy8vzgoKCqMto1TZsL+O3L63hH0s3k5OVwQ3nDOKGcwfROTsz6tJEJCRmtsjd8xLNS+aQ0IIG5MnE2gwgdkYgbUTxrv38/uW1PLm4mKz0NL523rF87bzBdMvJiro0EYlQMgFxK/BD4JngEtFgYF64ZUlz2Lq3nAfmrWX6gkIM4z/OHMA3LxhCr056WY+IJBEQ7v4a8BqAmaUB2939v8IuTMKzo7SCP7y2jr/O30hNrXPt6f24+cIhHNO1fdSliUgLksxdTNOArwM1xBqoO5vZb939l2EXJ01rz/4qHnpjPQ//ewPlVTVcfWou37p4KP176GU9IvJJyVxiOsHd95rZZOB54HZgEaCAaCVKK6r5y782MOWN9ewrr+byEUdz6yXDGNK7Y9SliUgLlkxAZJpZJnAVcL+7V5mZnlpuBQ5U1vDYW+/z4Kvr2LW/irEn9OHbY4dx/NGd619ZRFJeMgHxR+B9YCnwupkNAPaGWZQ0TkV1DTMWFHH/vLWU7KvgvGG9+M7YYZzSr2vUpYlIK5JMI/XvgN/FTdpoZheGV5I0VG2tM7OgiN+9/B6b95QzelB3Hpg0itGDukddmoi0Qsk0UvcB/i9wjLt/Onhvw5nAn8MuTo7M9IWF/PiZ5Yzs15V7xp/C2UN6qOttEWmwZHpbe4RYdxnHBONriD0bIS2Iu/PY/I2ceExnnvnmWZyjF/aISCMlExA93X0mUAuxPpaI3fIqLcjiwt2s+mAfk8cMUDCISJNIJiDKzKwHsc70MLMzgD2hViVHbGr+RnKy0rli5DH1LywikoRk7mL6NjALONbM/g30AsaHWpUckd37K3lu2RbGn5ZLR/W4KiJNJJm7mBab2fnAcYABq5N4F4Q0o6cWb6KiupZJY/TaVRFpOskebo4GBgbLjzIz3P2voVUlSXN3puVvZGS/rpx4TJeoyxGRNiSZ21wfA44FlvBR47QDCogWIH/DTtaVlPHL8SOiLkVE2phkziDyiPXHpO41WqBp+YV0ys7g8hFqnBaRppXMXUzLgaPCLkSO3PbSCp5fvoXPj8qlfZbe4SQiTSuZM4iewEozWwBUHJzo7leEVpUk5clFxVTVOJPVOC0iIUgmIO4Muwg5crW1zvQFhYwe2J2hfTpFXY6ItEHJXGK6zN1fi/8BLgu7MDm8f6/bzsYd+3Vrq4iEJpmAGJtg2qebuhA5MtPyC+nWIZNxJ6l5SETCcchLTGb2DeCbwGAzWxY3qxPw77ALk0PbtrecuSu38pWzB5KdqcZpEQnH4dogphF7xejPiL1m9KB97r4z1KrksGYWFFFT60wcrctLIhKew11icnd/H7gJ2Bf3g5kl9QYaMxtnZqvNbK2Z3Z5gfn8zm2dmb5vZMjO7LG7eD4P1VpvZp47kS7VlNbXO9AVFnD2kB4N76Z3SIhKe+s4gLgcWJZjnwODDbdjM0oEHiLVhFAMLzWyWu6+MW+wnwEx3fzB4EdFsYGAwPAE4kdh7KF4ys2HunvLdjL++poRNuw/wo8uOj7oUEWnjDhcQdwO4+6AGbns0sNbd1wOY2QzgSiA+IBzoHAx3ATYHw1cCM9y9AthgZmuD7c1vYC1txtT8jfTs2I6xJ/SJuhQRaeMOd4npgYMDZtaQHXNfoChuvDiYFu9O4ItmVkzs7OGWI1gXM7vRzArMrKCkpKQBJbYum3cf4JVV27g2L5esjGRuQBMRabjD7WXiX0uWHdLnTwQecfdcYs9WPGZmSe/53H2Ku+e5e16vXr1CKrHlmLGwCAc1TotIszjcJaY0M+tGLEQODn8YGkncybQJ6Bc3nhtMi3cDMC7Y3nwzyybWtUcy66aU6ppaHl9YyHlDe9Gve4eoyxGRFHC4o/UuxBqoC4i1EywOxg9Oq89CYKiZDTKzLGKNzrPqLFMIXAxgZscTO1MpCZabYGbtzGwQMBRYkOyXaoteXrWNrXsr1O+SiDSbQ55BuPvAxmzY3avN7GZgDpAOPOzuK8zsLqDA3WcB3wEeMrPbiDVYXx90K77CzGYSa9CuBm5K9TuYpuYXclTnbC4a3jvqUkQkRYT6AmN3n02s8Tl+2h1xwyuBsw+x7t0Ed1KlusId+3njvRL+66KhZKSrcVpEmof2Nq3A9IWFGDBhdL96lxURaSoKiBausrqWJwqKuGh4H47u0j7qckQkhSQVEGZ2jpl9ORjuFTQcSzOYu/IDtpdWMvkMNU6LSPOqNyDM7KfAD4AfBpMygb+FWZR8ZFp+IX27tue8oW3/OQ8RaVmSOYO4GrgCKANw983EuvyWkK0vKeXNdTuYNKY/6WlW/woiIk0omYCoDG49dQAzywm3JDlo+oJCMtKMa/Jyoy5FRFJQMgEx08z+CHQ1s68CLwEPhVuWlFfV8MSiYi49sQ+9O4XV04mIyKHV+xyEu//KzMYCe4HjgDvc/cXQK0txzy/fwu79VUwaPSDqUkQkRSX1oFwQCAqFZjQtv5CBPTpw1rE9oi5FRFJUMncx7TOzvXV+iszsGTM77EuDpGHWbN3Hwvd3MXF0f9LUOC0iEUnmDOI3xN7HMI1Yb64TgGOJdd73MHBBWMWlqmn5hWSlpzH+NDVOi0h0kmmkvsLd/+ju+9x9r7tPAT7l7o8D3UKuL+UcqKzhqcXFfPrko+jRsV3U5YhICksmIPab2bVmlhb8XAuUB/M8xNpS0rPLNrOvvJpJeimQiEQsmYCYDFwHbAO2BsNfNLP2wM0h1paSpuYXMqR3R0YP6h51KSKS4pK5zXU98NlDzP5X05aT2pZv2sPSot3ccfkJmKlxWkSiVW9ABK8BvQE4kbh3U7v7V0KsKyVNW1BIu4w0Pj9KjdMiEr1kLjE9BhwFfAp4jdj7ofeFWVQqKq2o5h9vb+LyEcfQpUNm1OWIiCQVEEPc/b+BMnd/FPgMMCbcslLPP5ZsoqyyRt16i0iLkUxAVAW/d5vZSUAXQC9GbkLuztS3Chl+VCdO7dc16nJERIDkAmKKmXUDfgLMAlYCvwi1qhSztHgPK7fsZfIZA9Q4LSItxmEbqc0sDdjr7ruA1wF1rRGCqW9tpENWOleNPCbqUkREPnTYMwh3rwW+30y1pKQ9B6p4dtlmrhx5DJ2y1TgtIi1HMpeYXjKz75pZPzPrfvAn9MpSxDOLiymvqlW33iLS4iTTWd8Xgt83xU1zdLmp0dydaQsKGZHbhZNzu0RdjojIx9R7BuHugxL8JBUOZjbOzFab2Vozuz3B/PvMbEnws8bMdsfNu8fMVpjZu2b2O2uDrbcFG3exZmspk8fo1lYRaXmSeZK6A/BtoL+732hmQ4Hj3P2f9ayXDjwAjCXWXfhCM5vl7isPLuPut8UtfwtwajB8FnA2MCKY/S/gfODV5L9ayzctv5BO7TL47ClqnBaRlieZNoi/AJXAWcH4JuB/k1hvNLDW3de7eyUwA7jyMMtPBKYHw06sW48soB2QSayjwDZjZ1klz72zhatH9aVDVlIv9hMRaVbJBMSx7n4PwQNz7r6f2IuD6tMXKIobLw6mfYKZDQAGAa8EnzEfmAdsCX7muPu7Cda70cwKzKygpKQkiZJajqcWFVNZXcskXV4SkRYqmYCoDLr2dgAzOxaoaOI6JgBPuntN8BlDgOOJ9fvUF7jIzM6tu5K7T3H3PHfP69WrVxOXFJ6DjdOnDejG8KM6R12OiEhCyQTEncALQD8zmwq8THLPRmwC+sWN5wbTEpnAR5eXAK4G3nL3UncvBZ4HzkziM1uF+et2sGF7mRqnRaRFS+YuprnA54Drie3E89z91SS2vRAYamaDzCyLWAjMqruQmQ0n9urS+XGTC4HzzSzDzDKJNVB/4hJTazV1QSFd2mdy2clHR12KiMgh1RsQZvYscCnwqrv/0923J7Nhd68m9sa5OcR27jPdfYWZ3WVmV8QtOgGY4e7xry99ElgHvAMsBZa6+7NJfaMWrmRfBXOWf8D403LJzkyPuhwRkUNK5vaZXxF7WO7nZraQ2N1I/3T38sOvBu4+G5hdZ9oddcbvTLBeDfC1JGprdZ5YVER1rTNR75wWkRYumVeOvga8FjzXcBHwVeBhQK2rR6i21pm+oJAzBndnSO+OUZcjInJYyTRSE9zF9Hng68DpwKNhFtVWvbF2O0U7DzBpjPpdEpGWL5knqWcSe+jtBeB+4LWgl1c5QlPf2kiPnCw+dWKfqEsREalXMmcQfyb2sNzX3X0ecJaZPRByXW3OB3vKeXnVNsbn5dIuQ43TItLyJdMGMcfMTjWzicC1wAbg6dAra2MeX1hETa0zSY3TItJKHDIgzGwYsf6RJgLbgccBc/cLm6m2NqO6ppYZCws5d2hPBvTIibocEZGkHO4S0ypidy1d7u7nuPvvgZrmKatteXV1CVv2lOvJaRFpVQ4XEJ8j1lHePDN7yMwuJrlO+qSOqfkb6d2pHRcfr8ZpEWk9DhkQ7v53d58ADCfWs+qtQG8ze9DMLm2uAlu74l37eXVNCV84vR+Z6UndVSwi0iIk0xdTmbtPc/fPEutw723gB6FX1kbMWFCEARPUOC0ircwRHdK6+66gi+2LwyqoLamqqeXxgiIuOK43fbu2j7ocEZEjomseIXpp5VZK9lWocVpEWiUFRIimLSjkmC7ZXHBc76hLERE5YgqIkLy/vYw33tvOhNH9SU/TzV8i0vooIEIyfUEh6WnGF07vV//CIiItkAIiBBXVNTyxqJhLju9Nn87ZUZcjItIgCogQvLD8A3aWVTJZ3XqLSCumgAjBtPxC+nfvwDlDekZdiohIgykgmtjabfvI37CTiaP7k6bGaRFpxRQQTWxafhGZ6cY1eblRlyIi0igKiCZUXlXDk4uK+NSJR9GzY7uoyxERaRQFRBN6btkW9pZXM0lPTotIG6CAaEJT8zcyuGcOZw7uEXUpIiKNpoBoIu9u2cviwt1MGtMfMzVOi0jrF2pAmNk4M1ttZmvN7PYE8+8zsyXBzxoz2x03r7+ZzTWzd81spZkNDLPWxpqWX0hWRhrjT1PjtIi0DYd8J3VjmVk68AAwFigGFprZLHdfeXAZd78tbvlbgFPjNvFX4G53f9HMOgK1YdXaWGUV1Tzz9iYuP/lounbIirocEZEmEeYZxGhgrbuvd/dKYAZw5WGWnwhMBzCzE4AMd38RwN1L3X1/iLU2yrNLN1NaocZpEWlbwgyIvkBR3HhxMO0TzGwAMAh4JZg0DNhtZk+b2dtm9svgjKTuejeaWYGZFZSUlDRx+cmbml/IcX06cdqAbpHVICLS1FpKI/UE4El3rwnGM4Bzge8CpwODgevrrhS83S7P3fN69erVXLV+zLLi3byzaY8ap0WkzQkzIDYB8X1d5wbTEplAcHkpUAwsCS5PVQN/B0aFUmUjTcsvpH1mOlePSnhyJCLSaoUZEAuBoWY2yMyyiIXArLoLmdlwoBswv866Xc3s4GnBRcDKuutGbW95FbOWbuazpxxN5+zMqMsREWlSoQVEcOR/MzAHeBeY6e4rzOwuM7sibtEJwAx397h1a4hdXnrZzN4BDHgorFob6h9vb2J/ZY269RaRNim021wB3H02MLvOtDvqjN95iHVfBEaEVlwjuTtT8ws58ZjOjMjtEnU5IiJNrqU0Urc6iwt3s+qDfUweM0CN0yLSJikgGmhafiEd22Vwxchjoi5FRCQUCogG2L2/kn8u28yVI4+hY7tQr9KJiERGAdEATy3eREV1rRqnRaRNU0AcIXdnWv5GRvbrygnHdI66HBGR0CggjlD+hp2sKyljsvpdEpE2TgFxhKblF9IpO4PLR6hxWkTaNgXEEdhRWsHzy7fw+VG5tM/6RN+BIiJtigLiCDy5qJiqGtflJRFJCQqIJNXWOtMWFDJ6YHeG9ukUdTkiIqFTQCTpzXU72LhjP5PP0NmDiKQGBUSSpuZvpFuHTMaddFTUpYiINAsFRBK27S1n7sqtXJPXj3YZapwWkdSggFLHTh8AAAmJSURBVEjCzIIiamqdiaN1eUlEUocCoh41tc70BUWcPaQHg3rmRF2OiEizUUDU4/U1JWzafYBJo9XvkoikFgVEPabmb6Rnx3aMPaFP1KWIiDQrBcRhbN59gFdWbePavFyyMvSnEpHUor3eYcxYWISDGqdFJCUpIA6huqaWxxcWcv6wXvTr3iHqckREmp0C4hBeXrWNrXsrmKSzBxFJUQqIQ5iWX8hRnbO5aHjvqEsREYmEAiKBwh37ef29Er5wej8y0vUnEpHUpL1fAtMXFmLAhNH9oi5FRCQyoQaEmY0zs9VmttbMbk8w/z4zWxL8rDGz3XXmdzazYjO7P8w641VW1/JEQREXDe/D0V3aN9fHioi0OBlhbdjM0oEHgLFAMbDQzGa5+8qDy7j7bXHL3wKcWmcz/wd4PawaE5m78gO2l1aqW28RSXlhnkGMBta6+3p3rwRmAFceZvmJwPSDI2Z2GtAHmBtijZ8wLb+Qvl3bc97QXs35sSIiLU6YAdEXKIobLw6mfYKZDQAGAa8E42nAvcB3D/cBZnajmRWYWUFJSUmjC15fUsqb63YwaUx/0tOs0dsTEWnNWkoj9QTgSXevCca/Ccx29+LDreTuU9w9z93zevVq/BH/9AWFZKQZ1+TlNnpbIiKtXWhtEMAmIP42oNxgWiITgJvixs8EzjWzbwIdgSwzK3X3TzR0N5XyqhqeWFTMpSf2oXen7LA+RkSk1QgzIBYCQ81sELFgmABMqruQmQ0HugHzD05z98lx868H8sIMB4AXln/A7v1VTB6jbr1FRCDES0zuXg3cDMwB3gVmuvsKM7vLzK6IW3QCMMPdPaxakjE1fyMDe3TgzME9oixDRKTFCPMMAnefDcyuM+2OOuN31rONR4BHmri0j1mzdR8L39/Fjy4bTpoap0VEgJbTSB2pafmFZKWnMf40PTktInJQygfEgcoanlpczKdPPoruOVlRlyMi0mKkfEDsLa/i/GG9+OIZapwWEYkXahtEa9Cnczb3TxoVdRkiIi1Oyp9BiIhIYgoIERFJSAEhIiIJKSBERCQhBYSIiCSkgBARkYQUECIikpACQkREErKIO1FtMmZWAmxsxCZ6AtubqJwotZXvAfouLVVb+S5t5XtA477LAHdP+Ma1NhMQjWVmBe6eF3UdjdVWvgfou7RUbeW7tJXvAeF9F11iEhGRhBQQIiKSkALiI1OiLqCJtJXvAfouLVVb+S5t5XtASN9FbRAiIpKQziBERCQhBYSIiCSU8gFhZuPMbLWZrTWz26Oup6HM7GEz22Zmy6OupbHMrJ+ZzTOzlWa2wsy+FXVNDWFm2Wa2wMyWBt/jf6KuqbHMLN3M3jazf0ZdS2OY2ftm9o6ZLTGzgqjraQwz62pmT5rZKjN718zObLJtp3IbhJmlA2uAsUAxsBCY6O4rIy2sAczsPKAU+Ku7nxR1PY1hZkcDR7v7YjPrBCwCrmpt/13MzIAcdy81s0zgX8C33P2tiEtrMDP7NpAHdHb3y6Oup6HM7H0gz91b/YNyZvYo8Ia7/8nMsoAO7r67Kbad6mcQo4G17r7e3SuBGcCVEdfUIO7+OrAz6jqagrtvcffFwfA+4F2gb7RVHTmPKQ1GM4OfVntEZma5wGeAP0Vdi8SYWRfgPODPAO5e2VThAAqIvkBR3HgxrXBH1JaZ2UDgVCA/2koaJrgkswTYBrzo7q3yewR+A3wfqI26kCbgwFwzW2RmN0ZdTCMMAkqAvwSX/v5kZjlNtfFUDwhpwcysI/AUcKu77426noZw9xp3HwnkAqPNrFVe/jOzy4Ft7r4o6lqayDnuPgr4NHBTcIm2NcoARgEPuvupQBnQZG2pqR4Qm4B+ceO5wTSJWHDN/ilgqrs/HXU9jRWc9s8DxkVdSwOdDVwRXLufAVxkZn+LtqSGc/dNwe9twDPELje3RsVAcdyZ6ZPEAqNJpHpALASGmtmgoHFnAjAr4ppSXtC4+2fgXXf/ddT1NJSZ9TKzrsFwe2I3Q6yKtqqGcfcfunuuuw8k9u/kFXf/YsRlNYiZ5QQ3PxBcjrkUaJV3/7n7B0CRmR0XTLoYaLKbOTKaakOtkbtXm9nNwBwgHXjY3VdEXFaDmNl04AKgp5kVAz919z9HW1WDnQ1cB7wTXL8H+JG7z46wpoY4Gng0uFsuDZjp7q369tA2og/wTOw4hAxgmru/EG1JjXILMDU4yF0PfLmpNpzSt7mKiMihpfolJhEROQQFhIiIJKSAEBGRhBQQIiKSkAJCREQSUkBIyjGzPmY2zczWB10tzDezqyOq5QIzOytu/Otm9h9R1CJSV0o/ByGpJ3gI7+/Ao+4+KZg2ALgixM/McPfqQ8y+gFgvvG8CuPsfwqpD5EjpOQhJKWZ2MXCHu5+fYF468HNiO+12wAPu/kczuwC4E9gOnESs+/Evurub2WnAr4GOwfzr3X2Lmb0KLAHOAaYT61b+J0AWsAOYDLQH3gJqiHW4dguxJ2FL3f1XZjYS+APQAVgHfMXddwXbzgcuBLoCN7j7G2Z2IvCX4DPSgM+7+3tN85eTVKRLTJJqTgQWH2LeDcAedz8dOB34qpkNCuadCtwKnAAMBs4O+ov6PTDe3U8DHgbujttelrvnufu9xN4FcUbQodoM4Pvu/j6xALjP3Ue6+xt16vkr8AN3HwG8A/w0bl6Gu48Oajo4/evAb4POAfOI9dMj0mC6xCQpzcweIHaUXwlsBEaY2fhgdhdgaDBvgbsXB+ssAQYCu4mdUbwYdNuQDmyJ2/zjccO5wOPBy5CygA311NUF6OrurwWTHgWeiFvkYAeGi4JaAOYDPw7e2/C0zh6ksXQGIalmBXG9Xbr7TcQu6/QCDLglOJof6e6D3H1usGhF3DZqiB1cGbAibvmT3f3SuOXK4oZ/D9zv7icDXwOyG/k9DtZzsBbcfRqxtpQDwGwzu6iRnyEpTgEhqeYVINvMvhE3rUPwew7wjeDSEWY2rJ6Xr6wGeh18B7CZZQbtAIl04aOu5L8UN30f0Knuwu6+B9hlZucGk64DXqu7XDwzGwysd/ffAf8ARhxueZH6KCAkpXjsroyrgPPNbIOZLSB2+eYHxF6luRJYbGbLgT9ymMuwwWtqxwO/MLOlxBqlzzrE4ncCT5jZImKN2Qc9C1xtZkviwuCgLwG/NLNlwEjgrnq+3rXA8uAS2EnE2jBEGkx3MYmISEI6gxARkYQUECIikpACQkREElJAiIhIQgoIERFJSAEhIiIJKSBERCSh/w/z8mcrZ33ubAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[77, 12, 0.4855711141605901], [67, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901], [77, 12, 0.4855711141605901]]\n",
            "3:32:50.473046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "3:32:50.706283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([67, 12, 0.4855711141605901], (0.8636,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,)),\n",
              " ([77, 12, 0.4855711141605901], (0.8645,))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}